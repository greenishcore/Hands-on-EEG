{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-20T18:53:31.734088Z",
     "end_time": "2023-04-20T18:53:41.738500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)  # 取平均作为输出\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T18:55:52.553517Z",
     "end_time": "2023-04-20T18:55:52.578517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T18:56:26.228690Z",
     "end_time": "2023-04-20T18:56:26.261476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # 假设输入数据的维度为(batch_size, sequence_length, input_dim)\n",
    "batch_size = 16\n",
    "sequence_length = 1000\n",
    "input_dim = 32\n",
    "num_classes = 6\n",
    "d_model = 32  # Transformer模型中特征的维度\n",
    "nhead = 4  # 多头自注意力头数\n",
    "num_layers = 4  # Transformer编码器层数\n",
    "model = Transformer(d_model, nhead, num_layers).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T18:56:27.007508Z",
     "end_time": "2023-04-20T18:56:27.093103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('encoder_layer.self_attn.in_proj_weight',\n              tensor([[-0.0299,  0.0612, -0.1074,  ...,  0.1874, -0.1438,  0.1018],\n                      [-0.2022,  0.1797, -0.0896,  ...,  0.0619,  0.1461, -0.0290],\n                      [ 0.1697,  0.1872, -0.1305,  ...,  0.0373, -0.1238,  0.0025],\n                      ...,\n                      [ 0.0434, -0.0207, -0.1276,  ..., -0.2075, -0.1074,  0.0820],\n                      [-0.0797,  0.0602, -0.1537,  ..., -0.1581, -0.0481, -0.1953],\n                      [-0.1915,  0.0174,  0.1310,  ...,  0.0938, -0.1755, -0.0699]])),\n             ('encoder_layer.self_attn.in_proj_bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('encoder_layer.self_attn.out_proj.weight',\n              tensor([[ 0.0442,  0.0661, -0.0040,  ...,  0.1579,  0.1679, -0.1565],\n                      [-0.0869,  0.0993, -0.0980,  ..., -0.1229,  0.0861, -0.0749],\n                      [ 0.0053,  0.0901,  0.0523,  ..., -0.1508,  0.1694,  0.1212],\n                      ...,\n                      [-0.0729,  0.1392,  0.0677,  ..., -0.1376,  0.1651, -0.0069],\n                      [ 0.1157,  0.0458, -0.0585,  ...,  0.0957, -0.0399,  0.1544],\n                      [ 0.1302, -0.1556, -0.0507,  ..., -0.0380,  0.0024, -0.0520]])),\n             ('encoder_layer.self_attn.out_proj.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('encoder_layer.linear1.weight',\n              tensor([[-0.1237,  0.0499, -0.1630,  ..., -0.1528,  0.0133, -0.0794],\n                      [ 0.1681,  0.1307, -0.1386,  ...,  0.0991, -0.0515,  0.0485],\n                      [-0.1156,  0.0164, -0.1597,  ...,  0.0617, -0.0082,  0.1531],\n                      ...,\n                      [ 0.0532, -0.1464,  0.0787,  ...,  0.1167, -0.0852, -0.0752],\n                      [ 0.0141,  0.1348, -0.0979,  ...,  0.0422, -0.0998,  0.0778],\n                      [-0.0122, -0.0044,  0.0580,  ...,  0.0262, -0.1363,  0.0082]])),\n             ('encoder_layer.linear1.bias',\n              tensor([ 0.0215, -0.1281, -0.0230,  ...,  0.1088,  0.1021,  0.0992])),\n             ('encoder_layer.linear2.weight',\n              tensor([[-0.0188, -0.0035,  0.0003,  ..., -0.0050, -0.0206, -0.0119],\n                      [-0.0175,  0.0031,  0.0080,  ...,  0.0077, -0.0211,  0.0083],\n                      [-0.0212,  0.0017, -0.0121,  ..., -0.0100, -0.0142,  0.0166],\n                      ...,\n                      [-0.0006,  0.0021,  0.0044,  ..., -0.0220,  0.0149,  0.0134],\n                      [ 0.0168, -0.0084,  0.0013,  ..., -0.0155, -0.0053,  0.0093],\n                      [-0.0025, -0.0153,  0.0220,  ..., -0.0092, -0.0157,  0.0212]])),\n             ('encoder_layer.linear2.bias',\n              tensor([ 0.0086, -0.0005, -0.0008, -0.0122, -0.0132,  0.0094, -0.0139, -0.0006,\n                       0.0220, -0.0163,  0.0220,  0.0172, -0.0153, -0.0143, -0.0197,  0.0016,\n                      -0.0082,  0.0060,  0.0156,  0.0130, -0.0171, -0.0114,  0.0006,  0.0192,\n                       0.0092, -0.0036,  0.0017, -0.0191, -0.0216,  0.0092, -0.0094,  0.0049])),\n             ('encoder_layer.norm1.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('encoder_layer.norm1.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('encoder_layer.norm2.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('encoder_layer.norm2.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n              tensor([[-0.0299,  0.0612, -0.1074,  ...,  0.1874, -0.1438,  0.1018],\n                      [-0.2022,  0.1797, -0.0896,  ...,  0.0619,  0.1461, -0.0290],\n                      [ 0.1697,  0.1872, -0.1305,  ...,  0.0373, -0.1238,  0.0025],\n                      ...,\n                      [ 0.0434, -0.0207, -0.1276,  ..., -0.2075, -0.1074,  0.0820],\n                      [-0.0797,  0.0602, -0.1537,  ..., -0.1581, -0.0481, -0.1953],\n                      [-0.1915,  0.0174,  0.1310,  ...,  0.0938, -0.1755, -0.0699]])),\n             ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n              tensor([[ 0.0442,  0.0661, -0.0040,  ...,  0.1579,  0.1679, -0.1565],\n                      [-0.0869,  0.0993, -0.0980,  ..., -0.1229,  0.0861, -0.0749],\n                      [ 0.0053,  0.0901,  0.0523,  ..., -0.1508,  0.1694,  0.1212],\n                      ...,\n                      [-0.0729,  0.1392,  0.0677,  ..., -0.1376,  0.1651, -0.0069],\n                      [ 0.1157,  0.0458, -0.0585,  ...,  0.0957, -0.0399,  0.1544],\n                      [ 0.1302, -0.1556, -0.0507,  ..., -0.0380,  0.0024, -0.0520]])),\n             ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.0.linear1.weight',\n              tensor([[-0.1237,  0.0499, -0.1630,  ..., -0.1528,  0.0133, -0.0794],\n                      [ 0.1681,  0.1307, -0.1386,  ...,  0.0991, -0.0515,  0.0485],\n                      [-0.1156,  0.0164, -0.1597,  ...,  0.0617, -0.0082,  0.1531],\n                      ...,\n                      [ 0.0532, -0.1464,  0.0787,  ...,  0.1167, -0.0852, -0.0752],\n                      [ 0.0141,  0.1348, -0.0979,  ...,  0.0422, -0.0998,  0.0778],\n                      [-0.0122, -0.0044,  0.0580,  ...,  0.0262, -0.1363,  0.0082]])),\n             ('transformer_encoder.layers.0.linear1.bias',\n              tensor([ 0.0215, -0.1281, -0.0230,  ...,  0.1088,  0.1021,  0.0992])),\n             ('transformer_encoder.layers.0.linear2.weight',\n              tensor([[-0.0188, -0.0035,  0.0003,  ..., -0.0050, -0.0206, -0.0119],\n                      [-0.0175,  0.0031,  0.0080,  ...,  0.0077, -0.0211,  0.0083],\n                      [-0.0212,  0.0017, -0.0121,  ..., -0.0100, -0.0142,  0.0166],\n                      ...,\n                      [-0.0006,  0.0021,  0.0044,  ..., -0.0220,  0.0149,  0.0134],\n                      [ 0.0168, -0.0084,  0.0013,  ..., -0.0155, -0.0053,  0.0093],\n                      [-0.0025, -0.0153,  0.0220,  ..., -0.0092, -0.0157,  0.0212]])),\n             ('transformer_encoder.layers.0.linear2.bias',\n              tensor([ 0.0086, -0.0005, -0.0008, -0.0122, -0.0132,  0.0094, -0.0139, -0.0006,\n                       0.0220, -0.0163,  0.0220,  0.0172, -0.0153, -0.0143, -0.0197,  0.0016,\n                      -0.0082,  0.0060,  0.0156,  0.0130, -0.0171, -0.0114,  0.0006,  0.0192,\n                       0.0092, -0.0036,  0.0017, -0.0191, -0.0216,  0.0092, -0.0094,  0.0049])),\n             ('transformer_encoder.layers.0.norm1.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.0.norm1.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.0.norm2.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.0.norm2.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n              tensor([[-0.0299,  0.0612, -0.1074,  ...,  0.1874, -0.1438,  0.1018],\n                      [-0.2022,  0.1797, -0.0896,  ...,  0.0619,  0.1461, -0.0290],\n                      [ 0.1697,  0.1872, -0.1305,  ...,  0.0373, -0.1238,  0.0025],\n                      ...,\n                      [ 0.0434, -0.0207, -0.1276,  ..., -0.2075, -0.1074,  0.0820],\n                      [-0.0797,  0.0602, -0.1537,  ..., -0.1581, -0.0481, -0.1953],\n                      [-0.1915,  0.0174,  0.1310,  ...,  0.0938, -0.1755, -0.0699]])),\n             ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n              tensor([[ 0.0442,  0.0661, -0.0040,  ...,  0.1579,  0.1679, -0.1565],\n                      [-0.0869,  0.0993, -0.0980,  ..., -0.1229,  0.0861, -0.0749],\n                      [ 0.0053,  0.0901,  0.0523,  ..., -0.1508,  0.1694,  0.1212],\n                      ...,\n                      [-0.0729,  0.1392,  0.0677,  ..., -0.1376,  0.1651, -0.0069],\n                      [ 0.1157,  0.0458, -0.0585,  ...,  0.0957, -0.0399,  0.1544],\n                      [ 0.1302, -0.1556, -0.0507,  ..., -0.0380,  0.0024, -0.0520]])),\n             ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.1.linear1.weight',\n              tensor([[-0.1237,  0.0499, -0.1630,  ..., -0.1528,  0.0133, -0.0794],\n                      [ 0.1681,  0.1307, -0.1386,  ...,  0.0991, -0.0515,  0.0485],\n                      [-0.1156,  0.0164, -0.1597,  ...,  0.0617, -0.0082,  0.1531],\n                      ...,\n                      [ 0.0532, -0.1464,  0.0787,  ...,  0.1167, -0.0852, -0.0752],\n                      [ 0.0141,  0.1348, -0.0979,  ...,  0.0422, -0.0998,  0.0778],\n                      [-0.0122, -0.0044,  0.0580,  ...,  0.0262, -0.1363,  0.0082]])),\n             ('transformer_encoder.layers.1.linear1.bias',\n              tensor([ 0.0215, -0.1281, -0.0230,  ...,  0.1088,  0.1021,  0.0992])),\n             ('transformer_encoder.layers.1.linear2.weight',\n              tensor([[-0.0188, -0.0035,  0.0003,  ..., -0.0050, -0.0206, -0.0119],\n                      [-0.0175,  0.0031,  0.0080,  ...,  0.0077, -0.0211,  0.0083],\n                      [-0.0212,  0.0017, -0.0121,  ..., -0.0100, -0.0142,  0.0166],\n                      ...,\n                      [-0.0006,  0.0021,  0.0044,  ..., -0.0220,  0.0149,  0.0134],\n                      [ 0.0168, -0.0084,  0.0013,  ..., -0.0155, -0.0053,  0.0093],\n                      [-0.0025, -0.0153,  0.0220,  ..., -0.0092, -0.0157,  0.0212]])),\n             ('transformer_encoder.layers.1.linear2.bias',\n              tensor([ 0.0086, -0.0005, -0.0008, -0.0122, -0.0132,  0.0094, -0.0139, -0.0006,\n                       0.0220, -0.0163,  0.0220,  0.0172, -0.0153, -0.0143, -0.0197,  0.0016,\n                      -0.0082,  0.0060,  0.0156,  0.0130, -0.0171, -0.0114,  0.0006,  0.0192,\n                       0.0092, -0.0036,  0.0017, -0.0191, -0.0216,  0.0092, -0.0094,  0.0049])),\n             ('transformer_encoder.layers.1.norm1.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.1.norm1.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.1.norm2.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.1.norm2.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.2.self_attn.in_proj_weight',\n              tensor([[-0.0299,  0.0612, -0.1074,  ...,  0.1874, -0.1438,  0.1018],\n                      [-0.2022,  0.1797, -0.0896,  ...,  0.0619,  0.1461, -0.0290],\n                      [ 0.1697,  0.1872, -0.1305,  ...,  0.0373, -0.1238,  0.0025],\n                      ...,\n                      [ 0.0434, -0.0207, -0.1276,  ..., -0.2075, -0.1074,  0.0820],\n                      [-0.0797,  0.0602, -0.1537,  ..., -0.1581, -0.0481, -0.1953],\n                      [-0.1915,  0.0174,  0.1310,  ...,  0.0938, -0.1755, -0.0699]])),\n             ('transformer_encoder.layers.2.self_attn.in_proj_bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.2.self_attn.out_proj.weight',\n              tensor([[ 0.0442,  0.0661, -0.0040,  ...,  0.1579,  0.1679, -0.1565],\n                      [-0.0869,  0.0993, -0.0980,  ..., -0.1229,  0.0861, -0.0749],\n                      [ 0.0053,  0.0901,  0.0523,  ..., -0.1508,  0.1694,  0.1212],\n                      ...,\n                      [-0.0729,  0.1392,  0.0677,  ..., -0.1376,  0.1651, -0.0069],\n                      [ 0.1157,  0.0458, -0.0585,  ...,  0.0957, -0.0399,  0.1544],\n                      [ 0.1302, -0.1556, -0.0507,  ..., -0.0380,  0.0024, -0.0520]])),\n             ('transformer_encoder.layers.2.self_attn.out_proj.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.2.linear1.weight',\n              tensor([[-0.1237,  0.0499, -0.1630,  ..., -0.1528,  0.0133, -0.0794],\n                      [ 0.1681,  0.1307, -0.1386,  ...,  0.0991, -0.0515,  0.0485],\n                      [-0.1156,  0.0164, -0.1597,  ...,  0.0617, -0.0082,  0.1531],\n                      ...,\n                      [ 0.0532, -0.1464,  0.0787,  ...,  0.1167, -0.0852, -0.0752],\n                      [ 0.0141,  0.1348, -0.0979,  ...,  0.0422, -0.0998,  0.0778],\n                      [-0.0122, -0.0044,  0.0580,  ...,  0.0262, -0.1363,  0.0082]])),\n             ('transformer_encoder.layers.2.linear1.bias',\n              tensor([ 0.0215, -0.1281, -0.0230,  ...,  0.1088,  0.1021,  0.0992])),\n             ('transformer_encoder.layers.2.linear2.weight',\n              tensor([[-0.0188, -0.0035,  0.0003,  ..., -0.0050, -0.0206, -0.0119],\n                      [-0.0175,  0.0031,  0.0080,  ...,  0.0077, -0.0211,  0.0083],\n                      [-0.0212,  0.0017, -0.0121,  ..., -0.0100, -0.0142,  0.0166],\n                      ...,\n                      [-0.0006,  0.0021,  0.0044,  ..., -0.0220,  0.0149,  0.0134],\n                      [ 0.0168, -0.0084,  0.0013,  ..., -0.0155, -0.0053,  0.0093],\n                      [-0.0025, -0.0153,  0.0220,  ..., -0.0092, -0.0157,  0.0212]])),\n             ('transformer_encoder.layers.2.linear2.bias',\n              tensor([ 0.0086, -0.0005, -0.0008, -0.0122, -0.0132,  0.0094, -0.0139, -0.0006,\n                       0.0220, -0.0163,  0.0220,  0.0172, -0.0153, -0.0143, -0.0197,  0.0016,\n                      -0.0082,  0.0060,  0.0156,  0.0130, -0.0171, -0.0114,  0.0006,  0.0192,\n                       0.0092, -0.0036,  0.0017, -0.0191, -0.0216,  0.0092, -0.0094,  0.0049])),\n             ('transformer_encoder.layers.2.norm1.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.2.norm1.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.2.norm2.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.2.norm2.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.3.self_attn.in_proj_weight',\n              tensor([[-0.0299,  0.0612, -0.1074,  ...,  0.1874, -0.1438,  0.1018],\n                      [-0.2022,  0.1797, -0.0896,  ...,  0.0619,  0.1461, -0.0290],\n                      [ 0.1697,  0.1872, -0.1305,  ...,  0.0373, -0.1238,  0.0025],\n                      ...,\n                      [ 0.0434, -0.0207, -0.1276,  ..., -0.2075, -0.1074,  0.0820],\n                      [-0.0797,  0.0602, -0.1537,  ..., -0.1581, -0.0481, -0.1953],\n                      [-0.1915,  0.0174,  0.1310,  ...,  0.0938, -0.1755, -0.0699]])),\n             ('transformer_encoder.layers.3.self_attn.in_proj_bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.3.self_attn.out_proj.weight',\n              tensor([[ 0.0442,  0.0661, -0.0040,  ...,  0.1579,  0.1679, -0.1565],\n                      [-0.0869,  0.0993, -0.0980,  ..., -0.1229,  0.0861, -0.0749],\n                      [ 0.0053,  0.0901,  0.0523,  ..., -0.1508,  0.1694,  0.1212],\n                      ...,\n                      [-0.0729,  0.1392,  0.0677,  ..., -0.1376,  0.1651, -0.0069],\n                      [ 0.1157,  0.0458, -0.0585,  ...,  0.0957, -0.0399,  0.1544],\n                      [ 0.1302, -0.1556, -0.0507,  ..., -0.0380,  0.0024, -0.0520]])),\n             ('transformer_encoder.layers.3.self_attn.out_proj.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.3.linear1.weight',\n              tensor([[-0.1237,  0.0499, -0.1630,  ..., -0.1528,  0.0133, -0.0794],\n                      [ 0.1681,  0.1307, -0.1386,  ...,  0.0991, -0.0515,  0.0485],\n                      [-0.1156,  0.0164, -0.1597,  ...,  0.0617, -0.0082,  0.1531],\n                      ...,\n                      [ 0.0532, -0.1464,  0.0787,  ...,  0.1167, -0.0852, -0.0752],\n                      [ 0.0141,  0.1348, -0.0979,  ...,  0.0422, -0.0998,  0.0778],\n                      [-0.0122, -0.0044,  0.0580,  ...,  0.0262, -0.1363,  0.0082]])),\n             ('transformer_encoder.layers.3.linear1.bias',\n              tensor([ 0.0215, -0.1281, -0.0230,  ...,  0.1088,  0.1021,  0.0992])),\n             ('transformer_encoder.layers.3.linear2.weight',\n              tensor([[-0.0188, -0.0035,  0.0003,  ..., -0.0050, -0.0206, -0.0119],\n                      [-0.0175,  0.0031,  0.0080,  ...,  0.0077, -0.0211,  0.0083],\n                      [-0.0212,  0.0017, -0.0121,  ..., -0.0100, -0.0142,  0.0166],\n                      ...,\n                      [-0.0006,  0.0021,  0.0044,  ..., -0.0220,  0.0149,  0.0134],\n                      [ 0.0168, -0.0084,  0.0013,  ..., -0.0155, -0.0053,  0.0093],\n                      [-0.0025, -0.0153,  0.0220,  ..., -0.0092, -0.0157,  0.0212]])),\n             ('transformer_encoder.layers.3.linear2.bias',\n              tensor([ 0.0086, -0.0005, -0.0008, -0.0122, -0.0132,  0.0094, -0.0139, -0.0006,\n                       0.0220, -0.0163,  0.0220,  0.0172, -0.0153, -0.0143, -0.0197,  0.0016,\n                      -0.0082,  0.0060,  0.0156,  0.0130, -0.0171, -0.0114,  0.0006,  0.0192,\n                       0.0092, -0.0036,  0.0017, -0.0191, -0.0216,  0.0092, -0.0094,  0.0049])),\n             ('transformer_encoder.layers.3.norm1.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.3.norm1.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('transformer_encoder.layers.3.norm2.weight',\n              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n             ('transformer_encoder.layers.3.norm2.bias',\n              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                      0., 0., 0., 0., 0., 0., 0., 0.])),\n             ('fc.weight',\n              tensor([[ 1.1419e-01, -8.5616e-02, -4.4856e-02, -1.2534e-01, -9.1750e-02,\n                       -9.2200e-03,  2.9937e-02, -1.0026e-01, -1.0753e-01,  1.4776e-01,\n                        1.3461e-01, -9.0483e-02,  2.5837e-02, -1.6965e-01, -1.1305e-01,\n                        5.7421e-02, -4.7127e-02, -2.0099e-02, -7.3755e-02,  1.1230e-01,\n                        1.4994e-01, -2.4798e-02,  9.1310e-02, -4.9150e-02, -1.6556e-03,\n                        7.0877e-02, -9.9013e-02,  4.1845e-02, -1.2083e-01, -1.9219e-02,\n                        1.4639e-01, -1.2240e-01],\n                      [ 7.5886e-02,  1.0507e-01, -1.7333e-01,  1.1371e-01, -5.6823e-02,\n                        3.0297e-02, -1.0171e-01, -1.3389e-01, -6.8411e-02,  4.7047e-02,\n                        3.0708e-02, -1.3188e-01, -3.9474e-02, -1.5534e-01,  9.0594e-02,\n                       -6.8776e-02, -2.3552e-02, -5.1182e-02,  1.5244e-01, -1.6713e-01,\n                        1.7239e-01,  1.1911e-01,  1.3453e-01,  8.0212e-03, -9.5832e-02,\n                        6.5498e-03,  4.5648e-02,  1.3761e-01,  9.1861e-02,  3.8212e-02,\n                       -1.2514e-01,  2.3083e-02],\n                      [ 4.9054e-02,  7.0527e-02, -2.7233e-02,  1.2551e-01, -7.6751e-02,\n                        6.5114e-02, -1.6839e-01,  8.1279e-02, -1.2884e-01, -1.7234e-01,\n                       -7.6225e-02, -2.9287e-02,  1.7315e-01, -4.6572e-02,  1.3860e-01,\n                       -1.2604e-01,  7.2368e-03,  1.6766e-01, -7.4021e-02, -7.3921e-02,\n                       -6.7106e-02, -1.0044e-01,  1.0948e-01, -1.5655e-01, -1.0021e-01,\n                       -1.1717e-01,  7.7466e-02,  3.8521e-02, -1.5398e-01,  8.0990e-02,\n                       -1.0535e-02, -1.5152e-01],\n                      [-1.5765e-01, -5.5684e-03, -1.2315e-01,  3.7880e-02, -1.4822e-01,\n                        9.5804e-02, -4.4631e-02,  3.1276e-02, -1.7436e-01,  8.1498e-02,\n                       -9.1640e-03,  6.5515e-03, -7.4824e-02, -1.6414e-01,  3.6131e-02,\n                       -8.7985e-02,  9.6743e-02,  7.1333e-02, -2.5397e-02,  1.4417e-01,\n                        5.1116e-02, -1.6355e-01, -1.0903e-01,  1.5154e-01,  1.1424e-01,\n                       -1.6180e-01, -1.2812e-01,  1.4670e-01, -9.8236e-02, -8.4771e-02,\n                        5.7563e-02,  1.2344e-01],\n                      [ 1.8089e-02, -7.6550e-02, -6.2147e-02, -1.5609e-01, -7.0966e-02,\n                       -1.1801e-01,  6.0102e-02,  8.0904e-02,  9.9513e-02,  5.9233e-02,\n                       -1.3725e-02, -1.4868e-01,  6.2279e-02,  1.3099e-01,  1.6393e-01,\n                        7.5791e-02, -2.4259e-02, -1.0308e-01,  1.5019e-01, -7.5958e-02,\n                       -7.5526e-02, -1.0298e-01, -1.6816e-01, -1.7633e-01,  5.3433e-02,\n                       -1.5734e-01, -1.6906e-01,  5.6905e-02,  1.8503e-02, -7.2818e-02,\n                        1.5159e-01, -9.3217e-02],\n                      [-1.4872e-01, -1.5519e-01, -1.3241e-01, -8.2673e-02,  1.2122e-01,\n                        7.1951e-02,  9.9875e-02,  4.0529e-02, -1.6656e-01, -2.3874e-02,\n                        1.2625e-03, -1.0163e-01,  9.4322e-02, -4.8310e-02, -5.5755e-02,\n                        1.2148e-01, -3.2941e-02,  7.2501e-02, -2.7430e-02, -7.3937e-02,\n                       -7.0308e-03, -5.5419e-02, -1.6939e-01,  1.4978e-01, -1.0229e-01,\n                        3.8006e-02,  1.2736e-01, -3.0040e-02, -1.0383e-04,  1.4911e-01,\n                       -1.5031e-01,  1.2714e-01]])),\n             ('fc.bias',\n              tensor([-0.0480,  0.0742,  0.1644, -0.0211, -0.1712, -0.0033]))])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "from torch import nn\n",
    "save_path = \"C:\\\\Users\\\\a1882\\Desktop\\\\EEG\\\\model_saved\\\\transformer_1000_100e_1.pt\"\n",
    "onnx_file_name = \"./transformer_1000_100e__.onnx\"\n",
    "torch.load(save_path, map_location=torch.device('cpu'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T19:01:26.157490Z",
     "end_time": "2023-04-20T19:01:26.326059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# batch_size = 1\n",
    "# dummy_input = torch.randn(batch_size, 1000,32 ,requires_grad=True ,dtype=torch.float32)\n",
    "# output = model(dummy_input)\n",
    "# torch.onnx.export(model, dummy_input, onnx_file_name, verbose=True, input_names=['input'], output_names=['output'],\n",
    "#  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},opset_version=12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T19:03:13.819257Z",
     "end_time": "2023-04-20T19:03:13.842250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 32])\n",
      "tensor([[ 0.0413, -0.2721,  0.3691,  0.3503,  0.4697,  0.4085]])\n",
      "tensor([[0.1341, 0.0980, 0.1861, 0.1826, 0.2058, 0.1935]])\n",
      "walkl\n"
     ]
    }
   ],
   "source": [
    "signal = pd.read_csv(\"C:\\\\Users\\\\a1882\\Desktop\\EEG\\eegdata\\slice_data\\\\rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_14.csv\").T\n",
    "input = torch.from_numpy(signal.values)\n",
    "print(input.shape)\n",
    "input = input.unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    output = model(input.float())\n",
    "    print(output)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    print(probabilities)\n",
    "\n",
    "    _, pred = torch.max(output, dim=1)  # 找到预测分数最大的类别，得到预测类别\n",
    "\n",
    "    label_map = {0: 'lefthand', 1:'read' ,  2:'rest', 3: 'walkbase', 4: 'walkl' ,5: 'walkfocus'}\n",
    "    print(label_map[pred.item()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T20:35:07.176982Z",
     "end_time": "2023-04-20T20:35:07.530187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T19:46:22.104512Z",
     "end_time": "2023-04-20T19:46:22.173069Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
