{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.305835300Z",
     "start_time": "2023-05-14T02:04:22.262497300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "origin_raw_data_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\data\\\\1000_s100'\n",
    "model_save ='C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\model'\n",
    "pic_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\pic'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.365548800Z",
     "start_time": "2023-05-14T02:04:22.270281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = origin_raw_data_dir\n",
    "        self.file_list = os.listdir(self.data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = pd.read_csv(file_path, header=None)\n",
    "        data = data.values\n",
    "        data = torch.from_numpy(data)\n",
    "        label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "        data_label = label_map[file_name.split('_')[0]]\n",
    "        return data, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.365548800Z",
     "start_time": "2023-05-14T02:04:22.287006800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dataset = EEG_Dataset(origin_raw_data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.365548800Z",
     "start_time": "2023-05-14T02:04:22.302850800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(1, 4), stride=(1, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4))\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4))\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(15360, 128)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # print('x:', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print('conv1:', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        # print('pool1:', x.shape)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        # print('conv2:', x.shape)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        # print('pool2:', x.shape)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print('flatten:', x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print('fc1:', x.shape)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        # print('fc2:', x.shape)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.367054800Z",
     "start_time": "2023-05-14T02:04:22.322121700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=( 1, 32, 1000), dtype=torch.float32)\n",
    "model = EEGNet()\n",
    "output = model(X)\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.368058600Z",
     "start_time": "2023-05-14T02:04:22.331722400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.381622100Z",
     "start_time": "2023-05-14T02:04:22.363550400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.466870900Z",
     "start_time": "2023-05-14T02:04:22.378624600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            global train_loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "def test(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    global valid_loss\n",
    "    valid_loss.append(test_loss)\n",
    "    global accuracy\n",
    "    accuracy.append(correct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T02:04:22.467433500Z",
     "start_time": "2023-05-14T02:04:22.398746300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.830789  [    0/ 3599]\n",
      "loss: 1.634057  [  800/ 3599]\n",
      "loss: 0.941532  [ 1600/ 3599]\n",
      "loss: 0.815787  [ 2400/ 3599]\n",
      "loss: 0.198243  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 85.4%, Avg loss: 0.360864 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.285745  [    0/ 3599]\n",
      "loss: 0.745780  [  800/ 3599]\n",
      "loss: 0.228196  [ 1600/ 3599]\n",
      "loss: 0.209512  [ 2400/ 3599]\n",
      "loss: 0.675206  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 82.4%, Avg loss: 0.407916 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.189907  [    0/ 3599]\n",
      "loss: 0.149749  [  800/ 3599]\n",
      "loss: 0.706748  [ 1600/ 3599]\n",
      "loss: 0.190818  [ 2400/ 3599]\n",
      "loss: 0.297556  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 83.4%, Avg loss: 0.372698 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.593634  [    0/ 3599]\n",
      "loss: 1.609683  [  800/ 3599]\n",
      "loss: 0.080398  [ 1600/ 3599]\n",
      "loss: 0.305943  [ 2400/ 3599]\n",
      "loss: 0.018860  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 92.3%, Avg loss: 0.221005 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.506409  [    0/ 3599]\n",
      "loss: 0.379682  [  800/ 3599]\n",
      "loss: 0.534202  [ 1600/ 3599]\n",
      "loss: 0.218909  [ 2400/ 3599]\n",
      "loss: 0.746255  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 88.9%, Avg loss: 0.214477 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.512066  [    0/ 3599]\n",
      "loss: 0.003045  [  800/ 3599]\n",
      "loss: 0.234987  [ 1600/ 3599]\n",
      "loss: 0.243378  [ 2400/ 3599]\n",
      "loss: 0.134146  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 92.2%, Avg loss: 0.149407 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.037628  [    0/ 3599]\n",
      "loss: 0.025542  [  800/ 3599]\n",
      "loss: 0.395454  [ 1600/ 3599]\n",
      "loss: 0.133688  [ 2400/ 3599]\n",
      "loss: 0.306608  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 92.2%, Avg loss: 0.166983 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.258584  [    0/ 3599]\n",
      "loss: 0.212945  [  800/ 3599]\n",
      "loss: 0.020016  [ 1600/ 3599]\n",
      "loss: 0.230872  [ 2400/ 3599]\n",
      "loss: 1.186845  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 87.4%, Avg loss: 0.240951 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.225397  [    0/ 3599]\n",
      "loss: 0.582336  [  800/ 3599]\n",
      "loss: 0.496063  [ 1600/ 3599]\n",
      "loss: 0.026093  [ 2400/ 3599]\n",
      "loss: 0.021791  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 93.4%, Avg loss: 0.138450 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.229653  [    0/ 3599]\n",
      "loss: 0.189295  [  800/ 3599]\n",
      "loss: 0.564915  [ 1600/ 3599]\n",
      "loss: 0.497668  [ 2400/ 3599]\n",
      "loss: 0.651697  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 94.4%, Avg loss: 0.127961 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.184938  [    0/ 3599]\n",
      "loss: 0.247433  [  800/ 3599]\n",
      "loss: 0.035522  [ 1600/ 3599]\n",
      "loss: 0.076032  [ 2400/ 3599]\n",
      "loss: 0.567258  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 93.1%, Avg loss: 0.152042 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.047902  [    0/ 3599]\n",
      "loss: 0.602618  [  800/ 3599]\n",
      "loss: 0.269875  [ 1600/ 3599]\n",
      "loss: 0.204494  [ 2400/ 3599]\n",
      "loss: 0.307991  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 94.6%, Avg loss: 0.117307 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.570332  [    0/ 3599]\n",
      "loss: 0.198923  [  800/ 3599]\n",
      "loss: 0.003735  [ 1600/ 3599]\n",
      "loss: 0.008672  [ 2400/ 3599]\n",
      "loss: 0.103028  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 93.4%, Avg loss: 0.128065 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.201254  [    0/ 3599]\n",
      "loss: 0.235696  [  800/ 3599]\n",
      "loss: 0.013418  [ 1600/ 3599]\n",
      "loss: 0.064825  [ 2400/ 3599]\n",
      "loss: 0.123029  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 94.8%, Avg loss: 0.115921 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.103423  [    0/ 3599]\n",
      "loss: 0.005646  [  800/ 3599]\n",
      "loss: 0.140189  [ 1600/ 3599]\n",
      "loss: 0.180290  [ 2400/ 3599]\n",
      "loss: 0.021815  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 95.3%, Avg loss: 0.108258 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.144210  [    0/ 3599]\n",
      "loss: 0.034029  [  800/ 3599]\n",
      "loss: 1.003639  [ 1600/ 3599]\n",
      "loss: 0.429558  [ 2400/ 3599]\n",
      "loss: 0.232939  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.7%, Avg loss: 0.092319 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.131828  [    0/ 3599]\n",
      "loss: 0.164398  [  800/ 3599]\n",
      "loss: 0.494352  [ 1600/ 3599]\n",
      "loss: 0.105151  [ 2400/ 3599]\n",
      "loss: 0.174966  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 92.9%, Avg loss: 0.145308 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.011811  [    0/ 3599]\n",
      "loss: 0.070137  [  800/ 3599]\n",
      "loss: 0.310613  [ 1600/ 3599]\n",
      "loss: 0.062823  [ 2400/ 3599]\n",
      "loss: 0.036297  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 92.0%, Avg loss: 0.157211 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.016895  [    0/ 3599]\n",
      "loss: 0.102483  [  800/ 3599]\n",
      "loss: 0.464335  [ 1600/ 3599]\n",
      "loss: 0.158800  [ 2400/ 3599]\n",
      "loss: 0.000021  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.3%, Avg loss: 0.111918 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.678469  [    0/ 3599]\n",
      "loss: 0.110656  [  800/ 3599]\n",
      "loss: 0.014212  [ 1600/ 3599]\n",
      "loss: 0.089063  [ 2400/ 3599]\n",
      "loss: 0.156763  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.060182 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.046469  [    0/ 3599]\n",
      "loss: 0.191108  [  800/ 3599]\n",
      "loss: 0.884318  [ 1600/ 3599]\n",
      "loss: 0.001500  [ 2400/ 3599]\n",
      "loss: 0.046055  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.6%, Avg loss: 0.067629 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.009677  [    0/ 3599]\n",
      "loss: 0.038997  [  800/ 3599]\n",
      "loss: 0.166021  [ 1600/ 3599]\n",
      "loss: 0.052924  [ 2400/ 3599]\n",
      "loss: 1.027493  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.4%, Avg loss: 0.081926 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.611786  [    0/ 3599]\n",
      "loss: 0.119301  [  800/ 3599]\n",
      "loss: 0.407397  [ 1600/ 3599]\n",
      "loss: 0.382930  [ 2400/ 3599]\n",
      "loss: 0.259268  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 95.8%, Avg loss: 0.088919 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 3599]\n",
      "loss: 0.340244  [  800/ 3599]\n",
      "loss: 0.119007  [ 1600/ 3599]\n",
      "loss: 0.558338  [ 2400/ 3599]\n",
      "loss: 0.044586  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.8%, Avg loss: 0.076913 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.071011  [    0/ 3599]\n",
      "loss: 0.267810  [  800/ 3599]\n",
      "loss: 0.017948  [ 1600/ 3599]\n",
      "loss: 0.244991  [ 2400/ 3599]\n",
      "loss: 0.169145  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 95.4%, Avg loss: 0.095283 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.193870  [    0/ 3599]\n",
      "loss: 0.000014  [  800/ 3599]\n",
      "loss: 0.018390  [ 1600/ 3599]\n",
      "loss: 0.050556  [ 2400/ 3599]\n",
      "loss: 0.350622  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.083768 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.299642  [    0/ 3599]\n",
      "loss: 0.002684  [  800/ 3599]\n",
      "loss: 0.002426  [ 1600/ 3599]\n",
      "loss: 0.286200  [ 2400/ 3599]\n",
      "loss: 0.257133  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.1%, Avg loss: 0.071720 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.042530  [    0/ 3599]\n",
      "loss: 0.194076  [  800/ 3599]\n",
      "loss: 0.007323  [ 1600/ 3599]\n",
      "loss: 0.161970  [ 2400/ 3599]\n",
      "loss: 0.003931  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.061763 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.297125  [    0/ 3599]\n",
      "loss: 0.167102  [  800/ 3599]\n",
      "loss: 0.000001  [ 1600/ 3599]\n",
      "loss: 0.176498  [ 2400/ 3599]\n",
      "loss: 0.036534  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.192581 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.008084  [    0/ 3599]\n",
      "loss: 0.015839  [  800/ 3599]\n",
      "loss: 0.001070  [ 1600/ 3599]\n",
      "loss: 0.127212  [ 2400/ 3599]\n",
      "loss: 0.119992  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.062980 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.182288  [    0/ 3599]\n",
      "loss: 0.098988  [  800/ 3599]\n",
      "loss: 0.019255  [ 1600/ 3599]\n",
      "loss: 0.069437  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.6%, Avg loss: 0.059133 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.017562  [    0/ 3599]\n",
      "loss: 0.091775  [  800/ 3599]\n",
      "loss: 0.000416  [ 1600/ 3599]\n",
      "loss: 0.078527  [ 2400/ 3599]\n",
      "loss: 0.155369  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 95.8%, Avg loss: 0.091309 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/ 3599]\n",
      "loss: 0.044406  [  800/ 3599]\n",
      "loss: 0.050521  [ 1600/ 3599]\n",
      "loss: 0.098050  [ 2400/ 3599]\n",
      "loss: 0.190156  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 94.8%, Avg loss: 0.340157 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.132976  [    0/ 3599]\n",
      "loss: 0.014799  [  800/ 3599]\n",
      "loss: 0.059522  [ 1600/ 3599]\n",
      "loss: 0.024047  [ 2400/ 3599]\n",
      "loss: 0.003050  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 95.1%, Avg loss: 0.115461 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.062742  [    0/ 3599]\n",
      "loss: 0.168308  [  800/ 3599]\n",
      "loss: 0.085264  [ 1600/ 3599]\n",
      "loss: 0.088277  [ 2400/ 3599]\n",
      "loss: 0.215559  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.1%, Avg loss: 0.051204 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.224882  [    0/ 3599]\n",
      "loss: 0.076240  [  800/ 3599]\n",
      "loss: 0.000042  [ 1600/ 3599]\n",
      "loss: 0.125902  [ 2400/ 3599]\n",
      "loss: 0.002879  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.044157 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.008457  [    0/ 3599]\n",
      "loss: 0.001667  [  800/ 3599]\n",
      "loss: 0.045791  [ 1600/ 3599]\n",
      "loss: 0.139554  [ 2400/ 3599]\n",
      "loss: 0.000276  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.6%, Avg loss: 0.059998 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.059163  [    0/ 3599]\n",
      "loss: 0.014417  [  800/ 3599]\n",
      "loss: 0.285865  [ 1600/ 3599]\n",
      "loss: 0.028014  [ 2400/ 3599]\n",
      "loss: 0.538837  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.1%, Avg loss: 0.049510 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.000293  [    0/ 3599]\n",
      "loss: 0.000478  [  800/ 3599]\n",
      "loss: 0.126493  [ 1600/ 3599]\n",
      "loss: 0.197061  [ 2400/ 3599]\n",
      "loss: 0.000567  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.045528 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.304056  [    0/ 3599]\n",
      "loss: 0.604714  [  800/ 3599]\n",
      "loss: 0.000073  [ 1600/ 3599]\n",
      "loss: 1.102385  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.1%, Avg loss: 0.148859 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.044347  [    0/ 3599]\n",
      "loss: 0.000014  [  800/ 3599]\n",
      "loss: 0.066398  [ 1600/ 3599]\n",
      "loss: 0.021617  [ 2400/ 3599]\n",
      "loss: 0.074948  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.060305 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.012299  [    0/ 3599]\n",
      "loss: 0.172027  [  800/ 3599]\n",
      "loss: 0.104744  [ 1600/ 3599]\n",
      "loss: 0.384630  [ 2400/ 3599]\n",
      "loss: 0.152778  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.6%, Avg loss: 0.064265 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.060150  [    0/ 3599]\n",
      "loss: 0.057371  [  800/ 3599]\n",
      "loss: 0.084638  [ 1600/ 3599]\n",
      "loss: 0.069765  [ 2400/ 3599]\n",
      "loss: 0.188895  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.2%, Avg loss: 0.039777 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.001097  [    0/ 3599]\n",
      "loss: 0.043827  [  800/ 3599]\n",
      "loss: 0.026863  [ 1600/ 3599]\n",
      "loss: 0.098475  [ 2400/ 3599]\n",
      "loss: 0.045196  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.9%, Avg loss: 0.029868 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 3599]\n",
      "loss: 0.000089  [  800/ 3599]\n",
      "loss: 0.042564  [ 1600/ 3599]\n",
      "loss: 0.000694  [ 2400/ 3599]\n",
      "loss: 0.000041  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.6%, Avg loss: 0.030290 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.003548  [    0/ 3599]\n",
      "loss: 0.033099  [  800/ 3599]\n",
      "loss: 0.042146  [ 1600/ 3599]\n",
      "loss: 0.025704  [ 2400/ 3599]\n",
      "loss: 0.000556  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.044935 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.016796  [    0/ 3599]\n",
      "loss: 0.217616  [  800/ 3599]\n",
      "loss: 0.066968  [ 1600/ 3599]\n",
      "loss: 0.035544  [ 2400/ 3599]\n",
      "loss: 0.089786  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.060876 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.221918  [    0/ 3599]\n",
      "loss: 0.028338  [  800/ 3599]\n",
      "loss: 0.005568  [ 1600/ 3599]\n",
      "loss: 0.000089  [ 2400/ 3599]\n",
      "loss: 0.053450  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.055397 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.276524  [    0/ 3599]\n",
      "loss: 0.020996  [  800/ 3599]\n",
      "loss: 0.000400  [ 1600/ 3599]\n",
      "loss: 0.001996  [ 2400/ 3599]\n",
      "loss: 0.184419  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.045984 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.073994  [    0/ 3599]\n",
      "loss: 0.102160  [  800/ 3599]\n",
      "loss: 0.000183  [ 1600/ 3599]\n",
      "loss: 0.000003  [ 2400/ 3599]\n",
      "loss: 0.547437  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.4%, Avg loss: 0.035364 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.002450  [    0/ 3599]\n",
      "loss: 0.176058  [  800/ 3599]\n",
      "loss: 0.023457  [ 1600/ 3599]\n",
      "loss: 0.009695  [ 2400/ 3599]\n",
      "loss: 1.388817  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.6%, Avg loss: 0.043217 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.164595  [    0/ 3599]\n",
      "loss: 0.020050  [  800/ 3599]\n",
      "loss: 0.000278  [ 1600/ 3599]\n",
      "loss: 0.048425  [ 2400/ 3599]\n",
      "loss: 0.000186  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.1%, Avg loss: 0.052877 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.002333  [    0/ 3599]\n",
      "loss: 0.006893  [  800/ 3599]\n",
      "loss: 0.000000  [ 1600/ 3599]\n",
      "loss: 0.397884  [ 2400/ 3599]\n",
      "loss: 0.083162  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.041340 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.000025  [    0/ 3599]\n",
      "loss: 0.195578  [  800/ 3599]\n",
      "loss: 0.133961  [ 1600/ 3599]\n",
      "loss: 0.064049  [ 2400/ 3599]\n",
      "loss: 0.000139  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.057567 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.026441  [    0/ 3599]\n",
      "loss: 0.625539  [  800/ 3599]\n",
      "loss: 0.000254  [ 1600/ 3599]\n",
      "loss: 0.000185  [ 2400/ 3599]\n",
      "loss: 0.002459  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.9%, Avg loss: 0.038401 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/ 3599]\n",
      "loss: 0.000166  [  800/ 3599]\n",
      "loss: 0.287655  [ 1600/ 3599]\n",
      "loss: 0.053336  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.037825 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 3599]\n",
      "loss: 0.039280  [  800/ 3599]\n",
      "loss: 0.618258  [ 1600/ 3599]\n",
      "loss: 0.000000  [ 2400/ 3599]\n",
      "loss: 0.099459  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.104128 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000159  [    0/ 3599]\n",
      "loss: 0.000010  [  800/ 3599]\n",
      "loss: 0.034767  [ 1600/ 3599]\n",
      "loss: 0.002237  [ 2400/ 3599]\n",
      "loss: 0.001056  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.7%, Avg loss: 0.031555 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 3599]\n",
      "loss: 0.092416  [  800/ 3599]\n",
      "loss: 0.000000  [ 1600/ 3599]\n",
      "loss: 0.000149  [ 2400/ 3599]\n",
      "loss: 0.217096  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.031493 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 3599]\n",
      "loss: 0.010447  [  800/ 3599]\n",
      "loss: 0.030094  [ 1600/ 3599]\n",
      "loss: 0.415986  [ 2400/ 3599]\n",
      "loss: 0.188113  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.4%, Avg loss: 0.040209 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.470712  [    0/ 3599]\n",
      "loss: 0.003330  [  800/ 3599]\n",
      "loss: 0.260218  [ 1600/ 3599]\n",
      "loss: 0.000007  [ 2400/ 3599]\n",
      "loss: 0.314442  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.071013 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.187091  [    0/ 3599]\n",
      "loss: 0.000000  [  800/ 3599]\n",
      "loss: 0.024247  [ 1600/ 3599]\n",
      "loss: 0.020791  [ 2400/ 3599]\n",
      "loss: 0.370704  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.7%, Avg loss: 0.058350 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.001681  [    0/ 3599]\n",
      "loss: 0.001363  [  800/ 3599]\n",
      "loss: 0.000000  [ 1600/ 3599]\n",
      "loss: 0.100184  [ 2400/ 3599]\n",
      "loss: 0.000050  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.3%, Avg loss: 0.077433 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.074404  [    0/ 3599]\n",
      "loss: 0.077625  [  800/ 3599]\n",
      "loss: 0.000583  [ 1600/ 3599]\n",
      "loss: 0.002304  [ 2400/ 3599]\n",
      "loss: 0.017858  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.1%, Avg loss: 0.032908 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 3599]\n",
      "loss: 0.000149  [  800/ 3599]\n",
      "loss: 0.082979  [ 1600/ 3599]\n",
      "loss: 0.000240  [ 2400/ 3599]\n",
      "loss: 0.070264  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.143599 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000156  [    0/ 3599]\n",
      "loss: 0.002264  [  800/ 3599]\n",
      "loss: 0.002320  [ 1600/ 3599]\n",
      "loss: 0.000167  [ 2400/ 3599]\n",
      "loss: 0.185662  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.068032 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.011416  [    0/ 3599]\n",
      "loss: 0.049119  [  800/ 3599]\n",
      "loss: 0.120755  [ 1600/ 3599]\n",
      "loss: 0.669916  [ 2400/ 3599]\n",
      "loss: 0.120759  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.050208 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.041510  [    0/ 3599]\n",
      "loss: 0.005551  [  800/ 3599]\n",
      "loss: 0.099523  [ 1600/ 3599]\n",
      "loss: 0.107249  [ 2400/ 3599]\n",
      "loss: 0.001281  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.3%, Avg loss: 0.037304 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 3599]\n",
      "loss: 0.000094  [  800/ 3599]\n",
      "loss: 0.000004  [ 1600/ 3599]\n",
      "loss: 0.002544  [ 2400/ 3599]\n",
      "loss: 0.163466  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.6%, Avg loss: 0.039144 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.002009  [    0/ 3599]\n",
      "loss: 0.025725  [  800/ 3599]\n",
      "loss: 0.000000  [ 1600/ 3599]\n",
      "loss: 0.000000  [ 2400/ 3599]\n",
      "loss: 0.000047  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.038065 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.346082  [    0/ 3599]\n",
      "loss: 0.336226  [  800/ 3599]\n",
      "loss: 0.000194  [ 1600/ 3599]\n",
      "loss: 0.011910  [ 2400/ 3599]\n",
      "loss: 0.003994  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.6%, Avg loss: 0.059931 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.082715  [    0/ 3599]\n",
      "loss: 0.416502  [  800/ 3599]\n",
      "loss: 0.038642  [ 1600/ 3599]\n",
      "loss: 0.010244  [ 2400/ 3599]\n",
      "loss: 0.511612  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.4%, Avg loss: 0.019301 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000052  [    0/ 3599]\n",
      "loss: 0.000641  [  800/ 3599]\n",
      "loss: 0.383971  [ 1600/ 3599]\n",
      "loss: 0.002091  [ 2400/ 3599]\n",
      "loss: 0.000006  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.046522 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 3599]\n",
      "loss: 0.033190  [  800/ 3599]\n",
      "loss: 0.002693  [ 1600/ 3599]\n",
      "loss: 0.000005  [ 2400/ 3599]\n",
      "loss: 0.000601  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.033639 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.004286  [    0/ 3599]\n",
      "loss: 0.000000  [  800/ 3599]\n",
      "loss: 0.155858  [ 1600/ 3599]\n",
      "loss: 0.096384  [ 2400/ 3599]\n",
      "loss: 0.004415  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.048858 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.023531  [    0/ 3599]\n",
      "loss: 0.000981  [  800/ 3599]\n",
      "loss: 0.092198  [ 1600/ 3599]\n",
      "loss: 0.000000  [ 2400/ 3599]\n",
      "loss: 0.000006  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.047609 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.142246  [    0/ 3599]\n",
      "loss: 0.013177  [  800/ 3599]\n",
      "loss: 0.020705  [ 1600/ 3599]\n",
      "loss: 0.000200  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.2%, Avg loss: 0.021918 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/ 3599]\n",
      "loss: 0.000013  [  800/ 3599]\n",
      "loss: 0.000089  [ 1600/ 3599]\n",
      "loss: 0.000762  [ 2400/ 3599]\n",
      "loss: 0.174494  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.8%, Avg loss: 0.023436 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/ 3599]\n",
      "loss: 0.010113  [  800/ 3599]\n",
      "loss: 0.062262  [ 1600/ 3599]\n",
      "loss: 0.000081  [ 2400/ 3599]\n",
      "loss: 0.037322  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.9%, Avg loss: 0.030280 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 3599]\n",
      "loss: 0.040087  [  800/ 3599]\n",
      "loss: 0.009831  [ 1600/ 3599]\n",
      "loss: 0.273050  [ 2400/ 3599]\n",
      "loss: 0.001263  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.1%, Avg loss: 0.053431 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.087710  [    0/ 3599]\n",
      "loss: 0.000341  [  800/ 3599]\n",
      "loss: 0.079896  [ 1600/ 3599]\n",
      "loss: 0.005154  [ 2400/ 3599]\n",
      "loss: 0.098917  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.063233 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.008413  [    0/ 3599]\n",
      "loss: 0.091721  [  800/ 3599]\n",
      "loss: 0.003298  [ 1600/ 3599]\n",
      "loss: 0.000001  [ 2400/ 3599]\n",
      "loss: 0.000002  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.047874 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.005916  [    0/ 3599]\n",
      "loss: 0.028796  [  800/ 3599]\n",
      "loss: 0.047926  [ 1600/ 3599]\n",
      "loss: 0.102963  [ 2400/ 3599]\n",
      "loss: 0.000206  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.0%, Avg loss: 0.045364 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.092117  [    0/ 3599]\n",
      "loss: 0.000407  [  800/ 3599]\n",
      "loss: 0.112626  [ 1600/ 3599]\n",
      "loss: 0.155641  [ 2400/ 3599]\n",
      "loss: 0.000006  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.7%, Avg loss: 0.021481 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.123107  [    0/ 3599]\n",
      "loss: 0.000001  [  800/ 3599]\n",
      "loss: 0.000015  [ 1600/ 3599]\n",
      "loss: 0.119225  [ 2400/ 3599]\n",
      "loss: 0.006417  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.6%, Avg loss: 0.023241 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000768  [    0/ 3599]\n",
      "loss: 0.009714  [  800/ 3599]\n",
      "loss: 0.000097  [ 1600/ 3599]\n",
      "loss: 0.093332  [ 2400/ 3599]\n",
      "loss: 0.010333  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.058646 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.026522  [    0/ 3599]\n",
      "loss: 0.000556  [  800/ 3599]\n",
      "loss: 0.042973  [ 1600/ 3599]\n",
      "loss: 0.190782  [ 2400/ 3599]\n",
      "loss: 0.015470  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.6%, Avg loss: 0.038925 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000879  [    0/ 3599]\n",
      "loss: 0.000016  [  800/ 3599]\n",
      "loss: 0.109872  [ 1600/ 3599]\n",
      "loss: 0.042340  [ 2400/ 3599]\n",
      "loss: 0.016296  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.0%, Avg loss: 0.070536 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.003807  [    0/ 3599]\n",
      "loss: 0.000406  [  800/ 3599]\n",
      "loss: 0.019765  [ 1600/ 3599]\n",
      "loss: 0.204005  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.079390 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 3599]\n",
      "loss: 0.000018  [  800/ 3599]\n",
      "loss: 0.414164  [ 1600/ 3599]\n",
      "loss: 0.002032  [ 2400/ 3599]\n",
      "loss: 0.102686  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.2%, Avg loss: 0.027090 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.124258  [    0/ 3599]\n",
      "loss: 0.030117  [  800/ 3599]\n",
      "loss: 0.000010  [ 1600/ 3599]\n",
      "loss: 0.000050  [ 2400/ 3599]\n",
      "loss: 0.014572  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.3%, Avg loss: 0.043060 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000103  [    0/ 3599]\n",
      "loss: 0.002458  [  800/ 3599]\n",
      "loss: 0.041011  [ 1600/ 3599]\n",
      "loss: 0.000292  [ 2400/ 3599]\n",
      "loss: 0.000134  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.2%, Avg loss: 0.028000 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000030  [    0/ 3599]\n",
      "loss: 0.000548  [  800/ 3599]\n",
      "loss: 0.189312  [ 1600/ 3599]\n",
      "loss: 0.003971  [ 2400/ 3599]\n",
      "loss: 0.010827  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.7%, Avg loss: 0.047307 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000902  [    0/ 3599]\n",
      "loss: 0.056645  [  800/ 3599]\n",
      "loss: 0.139551  [ 1600/ 3599]\n",
      "loss: 0.524098  [ 2400/ 3599]\n",
      "loss: 0.001657  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.4%, Avg loss: 0.035343 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000719  [    0/ 3599]\n",
      "loss: 0.225009  [  800/ 3599]\n",
      "loss: 0.000570  [ 1600/ 3599]\n",
      "loss: 0.000820  [ 2400/ 3599]\n",
      "loss: 0.000000  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.047243 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.205803  [    0/ 3599]\n",
      "loss: 0.000126  [  800/ 3599]\n",
      "loss: 0.094567  [ 1600/ 3599]\n",
      "loss: 0.038670  [ 2400/ 3599]\n",
      "loss: 0.001054  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.6%, Avg loss: 0.038417 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.108011  [    0/ 3599]\n",
      "loss: 0.015004  [  800/ 3599]\n",
      "loss: 0.196088  [ 1600/ 3599]\n",
      "loss: 0.000579  [ 2400/ 3599]\n",
      "loss: 0.000033  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.6%, Avg loss: 0.035259 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000033  [    0/ 3599]\n",
      "loss: 0.000001  [  800/ 3599]\n",
      "loss: 0.272804  [ 1600/ 3599]\n",
      "loss: 0.000003  [ 2400/ 3599]\n",
      "loss: 0.000030  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.3%, Avg loss: 0.018941 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000158  [    0/ 3599]\n",
      "loss: 0.000002  [  800/ 3599]\n",
      "loss: 0.063668  [ 1600/ 3599]\n",
      "loss: 0.008634  [ 2400/ 3599]\n",
      "loss: 0.000021  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 99.7%, Avg loss: 0.015646 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 3599]\n",
      "loss: 0.535107  [  800/ 3599]\n",
      "loss: 0.023250  [ 1600/ 3599]\n",
      "loss: 0.020230  [ 2400/ 3599]\n",
      "loss: 0.000044  [ 3200/ 3599]\n",
      "Test Error:\n",
      " Accuracy: 98.2%, Avg loss: 0.045993 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "# model = model = EEG_LSTM(input_size=31000, hidden_size=128, num_layers=2,num_classes=train_class_number).to(device)\n",
    "model = model.cuda()\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracy = []\n",
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    model.train(True)\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    model.train(False)\n",
    "    test(test_loader, model, loss_fn)\n",
    "\n",
    "    if t > num_epochs-5:\n",
    "        torch.save(model.state_dict(), os.path.join(model_save,'cnn_1000_200e_'+str(t)+'.pt'))\n",
    "\n",
    "print(\"Done!\")\n",
    "train_loss=pd.DataFrame(train_loss)\n",
    "valid_loss=pd.DataFrame(valid_loss)\n",
    "accuracy=pd.DataFrame(accuracy)\n",
    "\n",
    "train_loss.to_csv(os.path.join(pic_dir,'cnn_1000_s100_tloss.csv'))\n",
    "valid_loss.to_csv(os.path.join(pic_dir,'cnn_1000_s100_vloss.csv'))\n",
    "accuracy.to_csv(os.path.join(pic_dir,'cnn_1000_s100_acc.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T05:59:53.996869600Z",
     "start_time": "2023-05-14T02:04:22.412338500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m hex_d2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#005943\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m----> 7\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mtrain_loss\u001B[49m, hex_d1, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_loss' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "hex_d1 = '#552a28'\n",
    "hex_d2 = '#005943'\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, hex_d1, label='train loss')\n",
    "plt.ylabel('train loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(valid_loss, hex_d2, label='valid loss')\n",
    "plt.ylabel('valid loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(pic_dir, 'cnn_1000_s100_loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:09:26.764691600Z",
     "start_time": "2023-05-14T06:09:25.347520300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m----> 6\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43maccuracy\u001B[49m, color \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#550300\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'accuracy' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy, color = '#550300', label='accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig('cnn_1000_s100_acc.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:09:54.575535800Z",
     "start_time": "2023-05-14T06:09:54.490053200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
