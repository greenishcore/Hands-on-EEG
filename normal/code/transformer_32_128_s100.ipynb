{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.584964600Z",
     "start_time": "2023-05-14T06:11:47.540351700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "origin_raw_data_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\data\\\\128_s100'\n",
    "model_save ='C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\model'\n",
    "pic_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\pic'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.606828300Z",
     "start_time": "2023-05-14T06:11:50.589163200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = origin_raw_data_dir\n",
    "        self.file_list = os.listdir(self.data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = pd.read_csv(file_path, header=None).T\n",
    "        data = data.values\n",
    "        data = torch.from_numpy(data)\n",
    "        label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "        data_label = label_map[file_name.split('_')[0]]\n",
    "        return data, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.619918Z",
     "start_time": "2023-05-14T06:11:50.601811800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = EEG_Dataset(origin_raw_data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.650772200Z",
     "start_time": "2023-05-14T06:11:50.616412500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.705174400Z",
     "start_time": "2023-05-14T06:11:50.664867800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)  # 取平均作为输出\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.705174400Z",
     "start_time": "2023-05-14T06:11:50.675620400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # 假设输入数据的维度为(batch_size, sequence_length, input_dim)\n",
    "batch_size = 16\n",
    "sequence_length = 128\n",
    "input_dim = 32\n",
    "num_classes = 6\n",
    "d_model = 32  # Transformer模型中特征的维度\n",
    "nhead = 4  # 多头自注意力头数\n",
    "num_layers = 4  # Transformer编码器层数\n",
    "model = Transformer(d_model, nhead, num_layers).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:50.924014200Z",
     "start_time": "2023-05-14T06:11:50.692622700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 128,32, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:53.394999700Z",
     "start_time": "2023-05-14T06:11:50.927717500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:53.439587700Z",
     "start_time": "2023-05-14T06:11:53.398052100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            global train_loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "def test(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    global valid_loss\n",
    "    valid_loss.append(test_loss)\n",
    "    global accuracy\n",
    "    accuracy.append(correct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T06:11:53.455136800Z",
     "start_time": "2023-05-14T06:11:53.420336400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.047655  [    0/ 3788]\n",
      "loss: 1.478428  [  800/ 3788]\n",
      "loss: 0.888851  [ 1600/ 3788]\n",
      "loss: 0.901500  [ 2400/ 3788]\n",
      "loss: 1.457227  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 77.7%, Avg loss: 0.721467 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.031072  [    0/ 3788]\n",
      "loss: 0.826485  [  800/ 3788]\n",
      "loss: 0.421705  [ 1600/ 3788]\n",
      "loss: 0.557797  [ 2400/ 3788]\n",
      "loss: 0.318934  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 83.1%, Avg loss: 0.507749 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.257577  [    0/ 3788]\n",
      "loss: 0.406764  [  800/ 3788]\n",
      "loss: 0.316758  [ 1600/ 3788]\n",
      "loss: 0.173654  [ 2400/ 3788]\n",
      "loss: 0.377128  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 86.8%, Avg loss: 0.398075 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.165219  [    0/ 3788]\n",
      "loss: 0.113587  [  800/ 3788]\n",
      "loss: 0.826958  [ 1600/ 3788]\n",
      "loss: 0.414009  [ 2400/ 3788]\n",
      "loss: 0.052062  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 85.2%, Avg loss: 0.400794 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.467395  [    0/ 3788]\n",
      "loss: 0.165581  [  800/ 3788]\n",
      "loss: 0.181619  [ 1600/ 3788]\n",
      "loss: 0.061838  [ 2400/ 3788]\n",
      "loss: 0.287249  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 87.5%, Avg loss: 0.316380 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.412698  [    0/ 3788]\n",
      "loss: 0.172426  [  800/ 3788]\n",
      "loss: 0.179584  [ 1600/ 3788]\n",
      "loss: 0.091957  [ 2400/ 3788]\n",
      "loss: 0.115171  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 89.3%, Avg loss: 0.286143 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.121108  [    0/ 3788]\n",
      "loss: 0.134862  [  800/ 3788]\n",
      "loss: 0.068660  [ 1600/ 3788]\n",
      "loss: 0.271374  [ 2400/ 3788]\n",
      "loss: 0.069489  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 90.5%, Avg loss: 0.243913 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.426845  [    0/ 3788]\n",
      "loss: 0.240753  [  800/ 3788]\n",
      "loss: 0.114190  [ 1600/ 3788]\n",
      "loss: 0.084953  [ 2400/ 3788]\n",
      "loss: 0.178173  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 90.4%, Avg loss: 0.243164 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.029619  [    0/ 3788]\n",
      "loss: 0.054938  [  800/ 3788]\n",
      "loss: 0.267002  [ 1600/ 3788]\n",
      "loss: 0.110392  [ 2400/ 3788]\n",
      "loss: 0.338459  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.3%, Avg loss: 0.205015 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.117203  [    0/ 3788]\n",
      "loss: 0.111743  [  800/ 3788]\n",
      "loss: 0.022649  [ 1600/ 3788]\n",
      "loss: 0.077382  [ 2400/ 3788]\n",
      "loss: 0.127630  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 90.6%, Avg loss: 0.248320 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.627920  [    0/ 3788]\n",
      "loss: 0.239380  [  800/ 3788]\n",
      "loss: 0.079064  [ 1600/ 3788]\n",
      "loss: 0.110260  [ 2400/ 3788]\n",
      "loss: 0.080647  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.5%, Avg loss: 0.212178 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.084655  [    0/ 3788]\n",
      "loss: 0.164970  [  800/ 3788]\n",
      "loss: 0.139317  [ 1600/ 3788]\n",
      "loss: 0.027900  [ 2400/ 3788]\n",
      "loss: 0.261307  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.2%, Avg loss: 0.192879 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.027543  [    0/ 3788]\n",
      "loss: 0.060970  [  800/ 3788]\n",
      "loss: 0.022571  [ 1600/ 3788]\n",
      "loss: 0.259454  [ 2400/ 3788]\n",
      "loss: 0.070372  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.6%, Avg loss: 0.190539 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.078538  [    0/ 3788]\n",
      "loss: 0.045000  [  800/ 3788]\n",
      "loss: 0.044598  [ 1600/ 3788]\n",
      "loss: 0.112346  [ 2400/ 3788]\n",
      "loss: 0.161201  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.5%, Avg loss: 0.183172 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.069105  [    0/ 3788]\n",
      "loss: 0.064308  [  800/ 3788]\n",
      "loss: 0.020334  [ 1600/ 3788]\n",
      "loss: 0.103319  [ 2400/ 3788]\n",
      "loss: 0.247851  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 91.9%, Avg loss: 0.212412 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.271637  [    0/ 3788]\n",
      "loss: 0.295697  [  800/ 3788]\n",
      "loss: 0.061644  [ 1600/ 3788]\n",
      "loss: 0.035521  [ 2400/ 3788]\n",
      "loss: 0.025111  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.9%, Avg loss: 0.177196 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.144365  [    0/ 3788]\n",
      "loss: 0.098017  [  800/ 3788]\n",
      "loss: 0.029212  [ 1600/ 3788]\n",
      "loss: 0.005616  [ 2400/ 3788]\n",
      "loss: 0.262687  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.8%, Avg loss: 0.154332 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.007828  [    0/ 3788]\n",
      "loss: 0.502960  [  800/ 3788]\n",
      "loss: 0.390946  [ 1600/ 3788]\n",
      "loss: 0.048052  [ 2400/ 3788]\n",
      "loss: 0.013030  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.9%, Avg loss: 0.185828 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.006064  [    0/ 3788]\n",
      "loss: 0.035059  [  800/ 3788]\n",
      "loss: 0.016025  [ 1600/ 3788]\n",
      "loss: 0.006091  [ 2400/ 3788]\n",
      "loss: 0.018646  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.1%, Avg loss: 0.172707 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.061223  [    0/ 3788]\n",
      "loss: 0.012588  [  800/ 3788]\n",
      "loss: 0.196533  [ 1600/ 3788]\n",
      "loss: 0.112314  [ 2400/ 3788]\n",
      "loss: 0.071221  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.6%, Avg loss: 0.142572 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.005670  [    0/ 3788]\n",
      "loss: 0.172119  [  800/ 3788]\n",
      "loss: 0.384932  [ 1600/ 3788]\n",
      "loss: 0.011925  [ 2400/ 3788]\n",
      "loss: 0.469303  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.3%, Avg loss: 0.156346 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.234402  [    0/ 3788]\n",
      "loss: 0.045182  [  800/ 3788]\n",
      "loss: 0.035143  [ 1600/ 3788]\n",
      "loss: 0.014446  [ 2400/ 3788]\n",
      "loss: 0.176910  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.1%, Avg loss: 0.130964 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.110379  [    0/ 3788]\n",
      "loss: 0.023411  [  800/ 3788]\n",
      "loss: 0.075021  [ 1600/ 3788]\n",
      "loss: 0.320515  [ 2400/ 3788]\n",
      "loss: 0.006861  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.9%, Avg loss: 0.136986 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.006395  [    0/ 3788]\n",
      "loss: 0.068165  [  800/ 3788]\n",
      "loss: 0.039804  [ 1600/ 3788]\n",
      "loss: 0.034497  [ 2400/ 3788]\n",
      "loss: 0.028378  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.0%, Avg loss: 0.168292 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.041113  [    0/ 3788]\n",
      "loss: 0.039244  [  800/ 3788]\n",
      "loss: 0.034805  [ 1600/ 3788]\n",
      "loss: 0.038046  [ 2400/ 3788]\n",
      "loss: 0.008393  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.1%, Avg loss: 0.144305 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.008382  [    0/ 3788]\n",
      "loss: 0.028439  [  800/ 3788]\n",
      "loss: 0.010785  [ 1600/ 3788]\n",
      "loss: 0.006294  [ 2400/ 3788]\n",
      "loss: 0.020565  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.2%, Avg loss: 0.141565 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.011674  [    0/ 3788]\n",
      "loss: 0.011687  [  800/ 3788]\n",
      "loss: 0.313688  [ 1600/ 3788]\n",
      "loss: 0.031159  [ 2400/ 3788]\n",
      "loss: 0.271293  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.7%, Avg loss: 0.102874 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.105925  [    0/ 3788]\n",
      "loss: 0.053550  [  800/ 3788]\n",
      "loss: 0.697029  [ 1600/ 3788]\n",
      "loss: 0.011226  [ 2400/ 3788]\n",
      "loss: 0.059745  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.3%, Avg loss: 0.156397 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.033527  [    0/ 3788]\n",
      "loss: 0.042985  [  800/ 3788]\n",
      "loss: 0.028220  [ 1600/ 3788]\n",
      "loss: 0.038267  [ 2400/ 3788]\n",
      "loss: 0.014354  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.9%, Avg loss: 0.128970 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.024508  [    0/ 3788]\n",
      "loss: 0.051207  [  800/ 3788]\n",
      "loss: 0.122024  [ 1600/ 3788]\n",
      "loss: 0.274902  [ 2400/ 3788]\n",
      "loss: 0.001309  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.4%, Avg loss: 0.133453 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.032789  [    0/ 3788]\n",
      "loss: 0.003475  [  800/ 3788]\n",
      "loss: 0.012039  [ 1600/ 3788]\n",
      "loss: 0.385458  [ 2400/ 3788]\n",
      "loss: 0.061246  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.5%, Avg loss: 0.141867 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.115659  [    0/ 3788]\n",
      "loss: 0.024758  [  800/ 3788]\n",
      "loss: 0.041622  [ 1600/ 3788]\n",
      "loss: 0.005429  [ 2400/ 3788]\n",
      "loss: 0.048292  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.3%, Avg loss: 0.096705 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.004724  [    0/ 3788]\n",
      "loss: 0.015890  [  800/ 3788]\n",
      "loss: 0.006712  [ 1600/ 3788]\n",
      "loss: 0.294250  [ 2400/ 3788]\n",
      "loss: 0.046396  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.7%, Avg loss: 0.121759 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.001126  [    0/ 3788]\n",
      "loss: 0.116926  [  800/ 3788]\n",
      "loss: 0.007817  [ 1600/ 3788]\n",
      "loss: 0.049041  [ 2400/ 3788]\n",
      "loss: 0.011447  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.6%, Avg loss: 0.114645 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.001605  [    0/ 3788]\n",
      "loss: 0.035662  [  800/ 3788]\n",
      "loss: 0.204806  [ 1600/ 3788]\n",
      "loss: 0.031742  [ 2400/ 3788]\n",
      "loss: 0.005778  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.0%, Avg loss: 0.110612 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.019831  [    0/ 3788]\n",
      "loss: 0.096089  [  800/ 3788]\n",
      "loss: 0.014623  [ 1600/ 3788]\n",
      "loss: 0.010133  [ 2400/ 3788]\n",
      "loss: 0.003242  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.2%, Avg loss: 0.108081 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.005290  [    0/ 3788]\n",
      "loss: 0.005430  [  800/ 3788]\n",
      "loss: 0.187790  [ 1600/ 3788]\n",
      "loss: 0.009678  [ 2400/ 3788]\n",
      "loss: 0.199332  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.5%, Avg loss: 0.096750 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.054031  [    0/ 3788]\n",
      "loss: 0.078029  [  800/ 3788]\n",
      "loss: 0.003707  [ 1600/ 3788]\n",
      "loss: 0.211519  [ 2400/ 3788]\n",
      "loss: 0.003809  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.1%, Avg loss: 0.113088 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.203325  [    0/ 3788]\n",
      "loss: 0.003991  [  800/ 3788]\n",
      "loss: 0.032939  [ 1600/ 3788]\n",
      "loss: 0.013635  [ 2400/ 3788]\n",
      "loss: 0.003217  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.6%, Avg loss: 0.113686 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.005764  [    0/ 3788]\n",
      "loss: 0.037728  [  800/ 3788]\n",
      "loss: 0.099521  [ 1600/ 3788]\n",
      "loss: 0.003708  [ 2400/ 3788]\n",
      "loss: 0.005192  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.072398 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.002518  [    0/ 3788]\n",
      "loss: 0.028816  [  800/ 3788]\n",
      "loss: 0.004833  [ 1600/ 3788]\n",
      "loss: 0.017414  [ 2400/ 3788]\n",
      "loss: 0.007170  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.076323 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.002188  [    0/ 3788]\n",
      "loss: 0.005729  [  800/ 3788]\n",
      "loss: 0.037841  [ 1600/ 3788]\n",
      "loss: 0.188677  [ 2400/ 3788]\n",
      "loss: 0.000855  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.6%, Avg loss: 0.166526 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.123073  [    0/ 3788]\n",
      "loss: 0.006470  [  800/ 3788]\n",
      "loss: 0.004796  [ 1600/ 3788]\n",
      "loss: 0.001979  [ 2400/ 3788]\n",
      "loss: 0.005220  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.9%, Avg loss: 0.090734 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.006054  [    0/ 3788]\n",
      "loss: 0.030535  [  800/ 3788]\n",
      "loss: 0.025255  [ 1600/ 3788]\n",
      "loss: 0.004761  [ 2400/ 3788]\n",
      "loss: 0.001336  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.7%, Avg loss: 0.096231 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.007717  [    0/ 3788]\n",
      "loss: 0.053236  [  800/ 3788]\n",
      "loss: 0.004876  [ 1600/ 3788]\n",
      "loss: 0.254462  [ 2400/ 3788]\n",
      "loss: 1.041575  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.3%, Avg loss: 0.114561 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.012371  [    0/ 3788]\n",
      "loss: 0.009403  [  800/ 3788]\n",
      "loss: 0.000681  [ 1600/ 3788]\n",
      "loss: 0.000846  [ 2400/ 3788]\n",
      "loss: 0.001353  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.083699 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.014807  [    0/ 3788]\n",
      "loss: 0.003118  [  800/ 3788]\n",
      "loss: 0.014453  [ 1600/ 3788]\n",
      "loss: 0.219791  [ 2400/ 3788]\n",
      "loss: 0.437165  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.4%, Avg loss: 0.095814 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.004146  [    0/ 3788]\n",
      "loss: 0.103629  [  800/ 3788]\n",
      "loss: 0.006343  [ 1600/ 3788]\n",
      "loss: 0.041666  [ 2400/ 3788]\n",
      "loss: 0.001173  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.083200 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.005991  [    0/ 3788]\n",
      "loss: 0.035060  [  800/ 3788]\n",
      "loss: 0.003066  [ 1600/ 3788]\n",
      "loss: 0.164407  [ 2400/ 3788]\n",
      "loss: 0.011298  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.5%, Avg loss: 0.126041 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.002455  [    0/ 3788]\n",
      "loss: 0.003550  [  800/ 3788]\n",
      "loss: 0.001235  [ 1600/ 3788]\n",
      "loss: 0.113662  [ 2400/ 3788]\n",
      "loss: 0.020306  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.0%, Avg loss: 0.104380 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.001120  [    0/ 3788]\n",
      "loss: 0.000667  [  800/ 3788]\n",
      "loss: 0.006098  [ 1600/ 3788]\n",
      "loss: 0.006170  [ 2400/ 3788]\n",
      "loss: 0.034999  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.6%, Avg loss: 0.084342 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.002218  [    0/ 3788]\n",
      "loss: 0.013412  [  800/ 3788]\n",
      "loss: 0.033793  [ 1600/ 3788]\n",
      "loss: 0.051869  [ 2400/ 3788]\n",
      "loss: 0.001468  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.083044 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.012506  [    0/ 3788]\n",
      "loss: 0.000375  [  800/ 3788]\n",
      "loss: 0.264135  [ 1600/ 3788]\n",
      "loss: 0.035076  [ 2400/ 3788]\n",
      "loss: 0.000572  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.4%, Avg loss: 0.085877 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.002693  [    0/ 3788]\n",
      "loss: 0.003607  [  800/ 3788]\n",
      "loss: 0.314100  [ 1600/ 3788]\n",
      "loss: 0.014910  [ 2400/ 3788]\n",
      "loss: 0.001144  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.062730 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.006122  [    0/ 3788]\n",
      "loss: 0.445757  [  800/ 3788]\n",
      "loss: 0.048509  [ 1600/ 3788]\n",
      "loss: 0.005248  [ 2400/ 3788]\n",
      "loss: 0.003317  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.8%, Avg loss: 0.094686 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.078028  [    0/ 3788]\n",
      "loss: 0.001138  [  800/ 3788]\n",
      "loss: 0.003641  [ 1600/ 3788]\n",
      "loss: 0.003190  [ 2400/ 3788]\n",
      "loss: 0.006456  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.076735 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000674  [    0/ 3788]\n",
      "loss: 0.081631  [  800/ 3788]\n",
      "loss: 0.020524  [ 1600/ 3788]\n",
      "loss: 0.000462  [ 2400/ 3788]\n",
      "loss: 0.000640  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.074258 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.017429  [    0/ 3788]\n",
      "loss: 0.000542  [  800/ 3788]\n",
      "loss: 0.158968  [ 1600/ 3788]\n",
      "loss: 0.002537  [ 2400/ 3788]\n",
      "loss: 0.004330  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.6%, Avg loss: 0.071163 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.002514  [    0/ 3788]\n",
      "loss: 0.003207  [  800/ 3788]\n",
      "loss: 0.010227  [ 1600/ 3788]\n",
      "loss: 0.003709  [ 2400/ 3788]\n",
      "loss: 0.004942  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.071464 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.061514  [    0/ 3788]\n",
      "loss: 0.007132  [  800/ 3788]\n",
      "loss: 0.010849  [ 1600/ 3788]\n",
      "loss: 0.000462  [ 2400/ 3788]\n",
      "loss: 0.176703  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.4%, Avg loss: 0.089442 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.002385  [    0/ 3788]\n",
      "loss: 0.001400  [  800/ 3788]\n",
      "loss: 0.001356  [ 1600/ 3788]\n",
      "loss: 0.000309  [ 2400/ 3788]\n",
      "loss: 0.338661  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.6%, Avg loss: 0.083307 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.001518  [    0/ 3788]\n",
      "loss: 0.000621  [  800/ 3788]\n",
      "loss: 0.001951  [ 1600/ 3788]\n",
      "loss: 0.008223  [ 2400/ 3788]\n",
      "loss: 0.097665  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.082671 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.019396  [    0/ 3788]\n",
      "loss: 0.111401  [  800/ 3788]\n",
      "loss: 0.000889  [ 1600/ 3788]\n",
      "loss: 0.006918  [ 2400/ 3788]\n",
      "loss: 0.000845  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.058433 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 3788]\n",
      "loss: 0.000780  [  800/ 3788]\n",
      "loss: 0.139173  [ 1600/ 3788]\n",
      "loss: 0.012824  [ 2400/ 3788]\n",
      "loss: 0.193566  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.1%, Avg loss: 0.070827 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.195295  [    0/ 3788]\n",
      "loss: 0.003483  [  800/ 3788]\n",
      "loss: 0.004039  [ 1600/ 3788]\n",
      "loss: 0.013852  [ 2400/ 3788]\n",
      "loss: 0.024475  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.5%, Avg loss: 0.096422 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.040704  [    0/ 3788]\n",
      "loss: 0.030777  [  800/ 3788]\n",
      "loss: 0.002163  [ 1600/ 3788]\n",
      "loss: 0.004729  [ 2400/ 3788]\n",
      "loss: 0.003586  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.076407 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.031742  [    0/ 3788]\n",
      "loss: 0.005146  [  800/ 3788]\n",
      "loss: 0.001796  [ 1600/ 3788]\n",
      "loss: 0.005665  [ 2400/ 3788]\n",
      "loss: 0.096034  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.075069 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.057293  [    0/ 3788]\n",
      "loss: 0.001329  [  800/ 3788]\n",
      "loss: 0.002013  [ 1600/ 3788]\n",
      "loss: 0.008789  [ 2400/ 3788]\n",
      "loss: 0.006658  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.079872 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.000421  [    0/ 3788]\n",
      "loss: 0.000183  [  800/ 3788]\n",
      "loss: 0.003684  [ 1600/ 3788]\n",
      "loss: 0.006083  [ 2400/ 3788]\n",
      "loss: 0.022031  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.083895 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.005279  [    0/ 3788]\n",
      "loss: 0.001104  [  800/ 3788]\n",
      "loss: 0.000275  [ 1600/ 3788]\n",
      "loss: 0.001770  [ 2400/ 3788]\n",
      "loss: 0.187017  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.074623 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.001987  [    0/ 3788]\n",
      "loss: 0.000570  [  800/ 3788]\n",
      "loss: 0.000297  [ 1600/ 3788]\n",
      "loss: 0.001232  [ 2400/ 3788]\n",
      "loss: 0.052766  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.8%, Avg loss: 0.123268 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.032926  [    0/ 3788]\n",
      "loss: 0.114104  [  800/ 3788]\n",
      "loss: 0.006874  [ 1600/ 3788]\n",
      "loss: 0.000468  [ 2400/ 3788]\n",
      "loss: 0.003394  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.092803 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.011963  [    0/ 3788]\n",
      "loss: 0.046962  [  800/ 3788]\n",
      "loss: 0.002857  [ 1600/ 3788]\n",
      "loss: 0.000146  [ 2400/ 3788]\n",
      "loss: 0.001633  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.6%, Avg loss: 0.102486 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.002046  [    0/ 3788]\n",
      "loss: 0.000528  [  800/ 3788]\n",
      "loss: 0.009613  [ 1600/ 3788]\n",
      "loss: 0.002703  [ 2400/ 3788]\n",
      "loss: 0.301287  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.081607 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.012308  [    0/ 3788]\n",
      "loss: 0.014534  [  800/ 3788]\n",
      "loss: 0.001646  [ 1600/ 3788]\n",
      "loss: 0.000607  [ 2400/ 3788]\n",
      "loss: 0.014059  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 98.0%, Avg loss: 0.072722 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.004194  [    0/ 3788]\n",
      "loss: 0.011355  [  800/ 3788]\n",
      "loss: 0.103847  [ 1600/ 3788]\n",
      "loss: 0.000789  [ 2400/ 3788]\n",
      "loss: 0.000822  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.088019 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000588  [    0/ 3788]\n",
      "loss: 0.004381  [  800/ 3788]\n",
      "loss: 0.004846  [ 1600/ 3788]\n",
      "loss: 0.009392  [ 2400/ 3788]\n",
      "loss: 0.002277  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.081458 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000146  [    0/ 3788]\n",
      "loss: 0.041629  [  800/ 3788]\n",
      "loss: 0.177721  [ 1600/ 3788]\n",
      "loss: 0.000587  [ 2400/ 3788]\n",
      "loss: 0.001004  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.3%, Avg loss: 0.128262 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.017861  [    0/ 3788]\n",
      "loss: 0.101681  [  800/ 3788]\n",
      "loss: 0.000151  [ 1600/ 3788]\n",
      "loss: 0.052159  [ 2400/ 3788]\n",
      "loss: 0.025451  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.091861 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000684  [    0/ 3788]\n",
      "loss: 0.016513  [  800/ 3788]\n",
      "loss: 0.001931  [ 1600/ 3788]\n",
      "loss: 0.000657  [ 2400/ 3788]\n",
      "loss: 0.018919  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.074377 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.003498  [    0/ 3788]\n",
      "loss: 0.000126  [  800/ 3788]\n",
      "loss: 0.000313  [ 1600/ 3788]\n",
      "loss: 0.000437  [ 2400/ 3788]\n",
      "loss: 0.007465  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.9%, Avg loss: 0.083162 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000274  [    0/ 3788]\n",
      "loss: 0.046860  [  800/ 3788]\n",
      "loss: 0.000572  [ 1600/ 3788]\n",
      "loss: 0.000450  [ 2400/ 3788]\n",
      "loss: 0.001214  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.3%, Avg loss: 0.091016 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001511  [    0/ 3788]\n",
      "loss: 0.001096  [  800/ 3788]\n",
      "loss: 0.004223  [ 1600/ 3788]\n",
      "loss: 0.000106  [ 2400/ 3788]\n",
      "loss: 0.001844  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.6%, Avg loss: 0.123868 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.013063  [    0/ 3788]\n",
      "loss: 0.013398  [  800/ 3788]\n",
      "loss: 0.002404  [ 1600/ 3788]\n",
      "loss: 0.000145  [ 2400/ 3788]\n",
      "loss: 0.000349  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.070094 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000260  [    0/ 3788]\n",
      "loss: 0.000691  [  800/ 3788]\n",
      "loss: 0.000100  [ 1600/ 3788]\n",
      "loss: 0.008155  [ 2400/ 3788]\n",
      "loss: 0.007115  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.4%, Avg loss: 0.080130 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000282  [    0/ 3788]\n",
      "loss: 0.002509  [  800/ 3788]\n",
      "loss: 0.000715  [ 1600/ 3788]\n",
      "loss: 0.047013  [ 2400/ 3788]\n",
      "loss: 0.026080  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.070314 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.000470  [    0/ 3788]\n",
      "loss: 0.003990  [  800/ 3788]\n",
      "loss: 0.021602  [ 1600/ 3788]\n",
      "loss: 0.001825  [ 2400/ 3788]\n",
      "loss: 0.003544  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.8%, Avg loss: 0.074559 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000254  [    0/ 3788]\n",
      "loss: 0.001320  [  800/ 3788]\n",
      "loss: 0.000722  [ 1600/ 3788]\n",
      "loss: 0.000395  [ 2400/ 3788]\n",
      "loss: 0.000183  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.7%, Avg loss: 0.077798 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.021123  [    0/ 3788]\n",
      "loss: 0.000116  [  800/ 3788]\n",
      "loss: 0.000125  [ 1600/ 3788]\n",
      "loss: 0.001263  [ 2400/ 3788]\n",
      "loss: 0.000208  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.4%, Avg loss: 0.097049 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.043076  [    0/ 3788]\n",
      "loss: 0.000685  [  800/ 3788]\n",
      "loss: 0.002268  [ 1600/ 3788]\n",
      "loss: 0.000458  [ 2400/ 3788]\n",
      "loss: 0.000857  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.101125 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.000164  [    0/ 3788]\n",
      "loss: 0.000294  [  800/ 3788]\n",
      "loss: 0.001448  [ 1600/ 3788]\n",
      "loss: 0.000208  [ 2400/ 3788]\n",
      "loss: 0.000242  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.085743 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.001748  [    0/ 3788]\n",
      "loss: 0.000564  [  800/ 3788]\n",
      "loss: 0.000475  [ 1600/ 3788]\n",
      "loss: 0.003529  [ 2400/ 3788]\n",
      "loss: 0.000208  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.1%, Avg loss: 0.099692 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000838  [    0/ 3788]\n",
      "loss: 0.001203  [  800/ 3788]\n",
      "loss: 0.217872  [ 1600/ 3788]\n",
      "loss: 0.002280  [ 2400/ 3788]\n",
      "loss: 0.000204  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.083582 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/ 3788]\n",
      "loss: 0.000719  [  800/ 3788]\n",
      "loss: 0.003361  [ 1600/ 3788]\n",
      "loss: 0.000936  [ 2400/ 3788]\n",
      "loss: 0.000186  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 98.3%, Avg loss: 0.087073 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000245  [    0/ 3788]\n",
      "loss: 0.000316  [  800/ 3788]\n",
      "loss: 0.000408  [ 1600/ 3788]\n",
      "loss: 0.049226  [ 2400/ 3788]\n",
      "loss: 0.000092  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.0%, Avg loss: 0.100055 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.194558  [    0/ 3788]\n",
      "loss: 0.000106  [  800/ 3788]\n",
      "loss: 0.000377  [ 1600/ 3788]\n",
      "loss: 0.000341  [ 2400/ 3788]\n",
      "loss: 0.000163  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.095958 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.140688  [    0/ 3788]\n",
      "loss: 0.000102  [  800/ 3788]\n",
      "loss: 0.000115  [ 1600/ 3788]\n",
      "loss: 0.000352  [ 2400/ 3788]\n",
      "loss: 0.003512  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.5%, Avg loss: 0.074088 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000591  [    0/ 3788]\n",
      "loss: 0.004509  [  800/ 3788]\n",
      "loss: 0.004132  [ 1600/ 3788]\n",
      "loss: 0.000203  [ 2400/ 3788]\n",
      "loss: 0.000599  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.9%, Avg loss: 0.076653 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000145  [    0/ 3788]\n",
      "loss: 0.000897  [  800/ 3788]\n",
      "loss: 0.000223  [ 1600/ 3788]\n",
      "loss: 0.000720  [ 2400/ 3788]\n",
      "loss: 0.000095  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 98.1%, Avg loss: 0.071262 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.000227  [    0/ 3788]\n",
      "loss: 0.419449  [  800/ 3788]\n",
      "loss: 0.000104  [ 1600/ 3788]\n",
      "loss: 0.000131  [ 2400/ 3788]\n",
      "loss: 0.004767  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.7%, Avg loss: 0.089229 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# model = model = EEG_LSTM(input_size=31000, hidden_size=128, num_layers=2,num_classes=train_class_number).to(device)\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracy = []\n",
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    model.train(True)\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    model.train(False)\n",
    "    test(test_loader, model, loss_fn)\n",
    "    if t > num_epochs-5:\n",
    "        torch.save(model.state_dict(), os.path.join(model_save,'transformer_32_128_s100'+str(t)+'.pt'))\n",
    "\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T07:04:16.480254500Z",
     "start_time": "2023-05-14T06:11:53.439587700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0    2.047655\n",
      "1    1.478428\n",
      "2    0.888851\n",
      "3    0.901500\n",
      "4    1.457227\n",
      "..        ...\n",
      "495  0.000227\n",
      "496  0.419449\n",
      "497  0.000104\n",
      "498  0.000131\n",
      "499  0.004767\n",
      "\n",
      "[500 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_loss=pd.DataFrame(train_loss)\n",
    "valid_loss=pd.DataFrame(valid_loss)\n",
    "accuracy=pd.DataFrame(accuracy)\n",
    "\n",
    "train_loss.to_csv(os.path.join(pic_dir,'transformer_128_s100_tloss.csv'))\n",
    "valid_loss.to_csv(os.path.join(pic_dir,'transformer_128_s100_vloss.csv'))\n",
    "accuracy.to_csv(os.path.join(pic_dir,'transformer_128_s100_acc.csv'))\n",
    "\n",
    "print(train_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T07:04:16.515172Z",
     "start_time": "2023-05-14T07:04:16.482764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, 'b', label='train loss')\n",
    "plt.ylabel('train loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(valid_loss, 'r', label='valid loss')\n",
    "plt.ylabel('valid loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(pic_dir,'transfomer_32_128_loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-14T07:04:16.515226800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy, 'b', label='accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(pic_dir,'transfomer_32_128_acc.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
