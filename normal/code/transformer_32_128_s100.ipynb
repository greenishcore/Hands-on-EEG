{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.162157900Z",
     "start_time": "2023-05-11T16:33:52.129845700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "origin_raw_data_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\data\\\\128_s100'\n",
    "model_save ='C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\model'\n",
    "pic_dir = 'C:\\\\Users\\\\14870\\\\PycharmProjects\\\\Hands-on-EEG\\\\normal\\\\pic'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.188988100Z",
     "start_time": "2023-05-11T16:33:52.140375400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = origin_raw_data_dir\n",
    "        self.file_list = os.listdir(self.data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = pd.read_csv(file_path, header=None).T\n",
    "        data = data.values\n",
    "        data = torch.from_numpy(data)\n",
    "        label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "        data_label = label_map[file_name.split('_')[0]]\n",
    "        return data, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.190987200Z",
     "start_time": "2023-05-11T16:33:52.156460300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "dataset = EEG_Dataset(origin_raw_data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.261905900Z",
     "start_time": "2023-05-11T16:33:52.171080700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.278392400Z",
     "start_time": "2023-05-11T16:33:52.264937500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)  # 取平均作为输出\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.323464Z",
     "start_time": "2023-05-11T16:33:52.280390400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # 假设输入数据的维度为(batch_size, sequence_length, input_dim)\n",
    "batch_size = 16\n",
    "sequence_length = 128\n",
    "input_dim = 32\n",
    "num_classes = 6\n",
    "d_model = 32  # Transformer模型中特征的维度\n",
    "nhead = 4  # 多头自注意力头数\n",
    "num_layers = 4  # Transformer编码器层数\n",
    "model = Transformer(d_model, nhead, num_layers).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.337088500Z",
     "start_time": "2023-05-11T16:33:52.296982400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 128,32, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.401742800Z",
     "start_time": "2023-05-11T16:33:52.327509500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.413303400Z",
     "start_time": "2023-05-11T16:33:52.359242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            global train_loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "def test(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    global valid_loss\n",
    "    valid_loss.append(test_loss)\n",
    "    global accuracy\n",
    "    accuracy.append(correct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:33:52.414302600Z",
     "start_time": "2023-05-11T16:33:52.378061500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.697961  [    0/ 3788]\n",
      "loss: 1.211473  [  800/ 3788]\n",
      "loss: 0.865500  [ 1600/ 3788]\n",
      "loss: 1.130158  [ 2400/ 3788]\n",
      "loss: 0.691701  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 78.1%, Avg loss: 0.672638 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.560595  [    0/ 3788]\n",
      "loss: 0.855989  [  800/ 3788]\n",
      "loss: 0.612377  [ 1600/ 3788]\n",
      "loss: 0.476037  [ 2400/ 3788]\n",
      "loss: 0.242186  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 83.8%, Avg loss: 0.478467 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.657606  [    0/ 3788]\n",
      "loss: 0.619860  [  800/ 3788]\n",
      "loss: 0.445848  [ 1600/ 3788]\n",
      "loss: 0.864320  [ 2400/ 3788]\n",
      "loss: 0.171324  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 86.2%, Avg loss: 0.407740 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.504572  [    0/ 3788]\n",
      "loss: 0.608999  [  800/ 3788]\n",
      "loss: 0.989208  [ 1600/ 3788]\n",
      "loss: 0.341752  [ 2400/ 3788]\n",
      "loss: 0.386531  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 86.6%, Avg loss: 0.353242 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.076262  [    0/ 3788]\n",
      "loss: 0.252359  [  800/ 3788]\n",
      "loss: 0.097509  [ 1600/ 3788]\n",
      "loss: 0.133711  [ 2400/ 3788]\n",
      "loss: 0.190743  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 90.0%, Avg loss: 0.280782 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.163462  [    0/ 3788]\n",
      "loss: 0.183903  [  800/ 3788]\n",
      "loss: 0.170642  [ 1600/ 3788]\n",
      "loss: 0.311816  [ 2400/ 3788]\n",
      "loss: 0.241008  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 90.3%, Avg loss: 0.255683 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.139623  [    0/ 3788]\n",
      "loss: 0.083499  [  800/ 3788]\n",
      "loss: 0.082632  [ 1600/ 3788]\n",
      "loss: 0.057187  [ 2400/ 3788]\n",
      "loss: 0.182421  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 91.3%, Avg loss: 0.213595 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.186689  [    0/ 3788]\n",
      "loss: 0.105257  [  800/ 3788]\n",
      "loss: 0.138119  [ 1600/ 3788]\n",
      "loss: 0.561859  [ 2400/ 3788]\n",
      "loss: 0.111420  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 91.8%, Avg loss: 0.204573 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.204363  [    0/ 3788]\n",
      "loss: 0.327659  [  800/ 3788]\n",
      "loss: 0.370156  [ 1600/ 3788]\n",
      "loss: 0.261243  [ 2400/ 3788]\n",
      "loss: 0.086182  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 91.4%, Avg loss: 0.202879 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.220799  [    0/ 3788]\n",
      "loss: 0.011628  [  800/ 3788]\n",
      "loss: 0.064868  [ 1600/ 3788]\n",
      "loss: 0.034670  [ 2400/ 3788]\n",
      "loss: 0.141304  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.2%, Avg loss: 0.179103 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.045519  [    0/ 3788]\n",
      "loss: 0.073128  [  800/ 3788]\n",
      "loss: 0.075968  [ 1600/ 3788]\n",
      "loss: 0.012652  [ 2400/ 3788]\n",
      "loss: 0.107358  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 92.9%, Avg loss: 0.184116 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.046023  [    0/ 3788]\n",
      "loss: 0.255010  [  800/ 3788]\n",
      "loss: 0.066724  [ 1600/ 3788]\n",
      "loss: 0.013294  [ 2400/ 3788]\n",
      "loss: 0.010046  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.5%, Avg loss: 0.170159 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.078824  [    0/ 3788]\n",
      "loss: 0.061948  [  800/ 3788]\n",
      "loss: 0.289398  [ 1600/ 3788]\n",
      "loss: 0.087405  [ 2400/ 3788]\n",
      "loss: 0.048252  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.9%, Avg loss: 0.157664 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.360592  [    0/ 3788]\n",
      "loss: 0.035437  [  800/ 3788]\n",
      "loss: 0.385226  [ 1600/ 3788]\n",
      "loss: 0.079428  [ 2400/ 3788]\n",
      "loss: 0.032462  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.1%, Avg loss: 0.177053 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.094514  [    0/ 3788]\n",
      "loss: 0.317540  [  800/ 3788]\n",
      "loss: 0.131618  [ 1600/ 3788]\n",
      "loss: 0.242912  [ 2400/ 3788]\n",
      "loss: 0.017755  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.5%, Avg loss: 0.170306 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.060113  [    0/ 3788]\n",
      "loss: 0.142971  [  800/ 3788]\n",
      "loss: 0.045581  [ 1600/ 3788]\n",
      "loss: 0.024686  [ 2400/ 3788]\n",
      "loss: 0.133494  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.8%, Avg loss: 0.168869 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.557877  [    0/ 3788]\n",
      "loss: 0.169189  [  800/ 3788]\n",
      "loss: 0.078218  [ 1600/ 3788]\n",
      "loss: 0.099897  [ 2400/ 3788]\n",
      "loss: 0.021793  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.9%, Avg loss: 0.154054 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.027831  [    0/ 3788]\n",
      "loss: 0.028639  [  800/ 3788]\n",
      "loss: 0.051858  [ 1600/ 3788]\n",
      "loss: 0.014617  [ 2400/ 3788]\n",
      "loss: 0.185989  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.5%, Avg loss: 0.168679 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.609317  [    0/ 3788]\n",
      "loss: 0.024225  [  800/ 3788]\n",
      "loss: 0.087685  [ 1600/ 3788]\n",
      "loss: 0.103720  [ 2400/ 3788]\n",
      "loss: 0.141698  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.7%, Avg loss: 0.157160 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.041752  [    0/ 3788]\n",
      "loss: 0.521232  [  800/ 3788]\n",
      "loss: 0.267152  [ 1600/ 3788]\n",
      "loss: 0.015333  [ 2400/ 3788]\n",
      "loss: 0.175761  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.2%, Avg loss: 0.130398 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.027675  [    0/ 3788]\n",
      "loss: 0.024716  [  800/ 3788]\n",
      "loss: 0.248446  [ 1600/ 3788]\n",
      "loss: 0.160682  [ 2400/ 3788]\n",
      "loss: 0.005393  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.1%, Avg loss: 0.124724 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.147269  [    0/ 3788]\n",
      "loss: 0.006646  [  800/ 3788]\n",
      "loss: 0.029704  [ 1600/ 3788]\n",
      "loss: 0.018378  [ 2400/ 3788]\n",
      "loss: 0.028996  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.7%, Avg loss: 0.126297 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.122694  [    0/ 3788]\n",
      "loss: 0.004581  [  800/ 3788]\n",
      "loss: 0.030110  [ 1600/ 3788]\n",
      "loss: 0.224035  [ 2400/ 3788]\n",
      "loss: 0.160082  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.8%, Avg loss: 0.141519 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.009059  [    0/ 3788]\n",
      "loss: 0.027480  [  800/ 3788]\n",
      "loss: 0.005916  [ 1600/ 3788]\n",
      "loss: 0.099911  [ 2400/ 3788]\n",
      "loss: 0.222823  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.1%, Avg loss: 0.143573 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.041173  [    0/ 3788]\n",
      "loss: 0.401918  [  800/ 3788]\n",
      "loss: 0.114689  [ 1600/ 3788]\n",
      "loss: 0.005985  [ 2400/ 3788]\n",
      "loss: 0.024566  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 93.8%, Avg loss: 0.136882 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.136536  [    0/ 3788]\n",
      "loss: 0.141510  [  800/ 3788]\n",
      "loss: 0.006122  [ 1600/ 3788]\n",
      "loss: 0.785718  [ 2400/ 3788]\n",
      "loss: 0.058724  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.0%, Avg loss: 0.141481 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.311907  [    0/ 3788]\n",
      "loss: 0.027142  [  800/ 3788]\n",
      "loss: 0.079424  [ 1600/ 3788]\n",
      "loss: 0.052757  [ 2400/ 3788]\n",
      "loss: 0.013238  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.2%, Avg loss: 0.125116 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.029516  [    0/ 3788]\n",
      "loss: 0.013264  [  800/ 3788]\n",
      "loss: 0.017165  [ 1600/ 3788]\n",
      "loss: 0.371428  [ 2400/ 3788]\n",
      "loss: 0.066050  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 94.9%, Avg loss: 0.128154 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.002979  [    0/ 3788]\n",
      "loss: 0.009383  [  800/ 3788]\n",
      "loss: 0.008694  [ 1600/ 3788]\n",
      "loss: 0.001561  [ 2400/ 3788]\n",
      "loss: 0.043702  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.9%, Avg loss: 0.108894 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.002036  [    0/ 3788]\n",
      "loss: 0.071788  [  800/ 3788]\n",
      "loss: 0.018733  [ 1600/ 3788]\n",
      "loss: 0.039076  [ 2400/ 3788]\n",
      "loss: 0.015193  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.1%, Avg loss: 0.141164 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.052339  [    0/ 3788]\n",
      "loss: 0.007752  [  800/ 3788]\n",
      "loss: 0.017373  [ 1600/ 3788]\n",
      "loss: 0.070640  [ 2400/ 3788]\n",
      "loss: 0.012285  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.9%, Avg loss: 0.104089 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.102037  [    0/ 3788]\n",
      "loss: 0.021412  [  800/ 3788]\n",
      "loss: 0.246736  [ 1600/ 3788]\n",
      "loss: 0.037126  [ 2400/ 3788]\n",
      "loss: 0.002714  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.0%, Avg loss: 0.127321 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.018831  [    0/ 3788]\n",
      "loss: 0.003629  [  800/ 3788]\n",
      "loss: 0.185449  [ 1600/ 3788]\n",
      "loss: 0.274361  [ 2400/ 3788]\n",
      "loss: 0.030580  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.2%, Avg loss: 0.108521 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.037741  [    0/ 3788]\n",
      "loss: 0.008482  [  800/ 3788]\n",
      "loss: 0.016531  [ 1600/ 3788]\n",
      "loss: 0.007566  [ 2400/ 3788]\n",
      "loss: 0.015172  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.0%, Avg loss: 0.129767 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.095070  [    0/ 3788]\n",
      "loss: 0.160368  [  800/ 3788]\n",
      "loss: 0.098578  [ 1600/ 3788]\n",
      "loss: 0.249141  [ 2400/ 3788]\n",
      "loss: 0.026769  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 95.9%, Avg loss: 0.113165 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.030389  [    0/ 3788]\n",
      "loss: 0.009203  [  800/ 3788]\n",
      "loss: 0.063708  [ 1600/ 3788]\n",
      "loss: 0.172810  [ 2400/ 3788]\n",
      "loss: 0.001566  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.8%, Avg loss: 0.096290 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.021405  [    0/ 3788]\n",
      "loss: 0.009613  [  800/ 3788]\n",
      "loss: 0.002728  [ 1600/ 3788]\n",
      "loss: 0.024943  [ 2400/ 3788]\n",
      "loss: 0.009860  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.2%, Avg loss: 0.117572 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.087694  [    0/ 3788]\n",
      "loss: 0.140784  [  800/ 3788]\n",
      "loss: 0.024057  [ 1600/ 3788]\n",
      "loss: 0.018593  [ 2400/ 3788]\n",
      "loss: 0.009347  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.0%, Avg loss: 0.123269 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.239601  [    0/ 3788]\n",
      "loss: 0.002215  [  800/ 3788]\n",
      "loss: 0.008929  [ 1600/ 3788]\n",
      "loss: 0.543095  [ 2400/ 3788]\n",
      "loss: 0.002569  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 97.4%, Avg loss: 0.084534 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.123864  [    0/ 3788]\n",
      "loss: 0.004957  [  800/ 3788]\n",
      "loss: 0.003446  [ 1600/ 3788]\n",
      "loss: 0.002918  [ 2400/ 3788]\n",
      "loss: 0.002839  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.2%, Avg loss: 0.125032 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.002860  [    0/ 3788]\n",
      "loss: 0.003673  [  800/ 3788]\n",
      "loss: 0.053255  [ 1600/ 3788]\n",
      "loss: 0.001513  [ 2400/ 3788]\n",
      "loss: 0.032780  [ 3200/ 3788]\n",
      "Test Error:\n",
      " Accuracy: 96.8%, Avg loss: 0.100833 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.189278  [    0/ 3788]\n",
      "loss: 0.056049  [  800/ 3788]\n",
      "loss: 0.028347  [ 1600/ 3788]\n",
      "loss: 0.018459  [ 2400/ 3788]\n",
      "loss: 0.016783  [ 3200/ 3788]\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# model = model = EEG_LSTM(input_size=31000, hidden_size=128, num_layers=2,num_classes=train_class_number).to(device)\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracy = []\n",
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    model.train(True)\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    model.train(False)\n",
    "    test(test_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-11T16:33:52.401742800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, 'b', label='train loss')\n",
    "plt.ylabel('train loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(valid_loss, 'r', label='valid loss')\n",
    "plt.ylabel('valid loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.save(os.path.join(pic_dir,'transfomer_32_128_loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy, 'b', label='accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.save(os.path.join(pic_dir,'transfomer_32_128_loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
