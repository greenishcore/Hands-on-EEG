{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.379837Z",
     "end_time": "2023-04-16T08:50:35.391837Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory is C:\\Users\\a1882\\Desktop\\EEG\n",
      "lefthand_zyy_04_epocflex_2023.03.22t16.48.29+08.00.md.bp.csv_0.csv\n",
      "lefthand_zyy_04_epocflex_2023.03.22t16.48.29+08.00.md.bp.csv_2.csv\n",
      "lefthand_zyy_04_epocflex_2023.03.22t16.48.29+08.00.md.bp.csv_3.csv\n",
      "lefthand_zyy_04_epocflex_2023.03.22t16.48.29+08.00.md.bp.csv_4.csv\n",
      "lefthand_zyy_05_epocflex_2023.03.22t16.50.54+08.00.md.bp.csv_1.csv\n",
      "lefthand_zyy_05_epocflex_2023.03.22t16.50.54+08.00.md.bp.csv_2.csv\n",
      "read_bke_01_epocflex_2023.03.22t15.41.00+08.00.md.bp.csv_0.csv\n",
      "read_bke_01_epocflex_2023.03.22t15.41.00+08.00.md.bp.csv_2.csv\n",
      "read_bke_01_epocflex_2023.03.22t15.41.00+08.00.md.bp.csv_3.csv\n",
      "read_bke_01_epocflex_2023.03.22t15.41.00+08.00.md.bp.csv_4.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_0.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_1.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_11.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_14.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_2.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_4.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_7.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_9.csv\n",
      "read_bke_03_epocflex_2023.03.22t16.04.38+08.00.md.bp.csv_0.csv\n",
      "read_bke_03_epocflex_2023.03.22t16.04.38+08.00.md.bp.csv_2.csv\n",
      "read_bke_03_epocflex_2023.03.22t16.04.38+08.00.md.bp.csv_3.csv\n",
      "read_bke_04_epocflex_2023.03.22t16.07.02+08.00.md.bp.csv_0.csv\n",
      "read_bke_04_epocflex_2023.03.22t16.07.02+08.00.md.bp.csv_1.csv\n",
      "read_bke_05_epocflex_2023.03.22t16.09.28+08.00.md.bp.csv_0.csv\n",
      "read_bke_05_epocflex_2023.03.22t16.09.28+08.00.md.bp.csv_1.csv\n",
      "read_bke_05_epocflex_2023.03.22t16.09.28+08.00.md.bp.csv_2.csv\n",
      "read_bke_05_epocflex_2023.03.22t16.09.28+08.00.md.bp.csv_3.csv\n",
      "read_bke_05_epocflex_2023.03.22t16.09.28+08.00.md.bp.csv_4.csv\n",
      "rest_cp_epocflex_2023.03.26t14.28.21+08.00.md.bp.csv_0.csv\n",
      "rest_cp_epocflex_2023.03.26t14.28.21+08.00.md.bp.csv_1.csv\n",
      "rest_cp_epocflex_2023.03.26t14.28.21+08.00.md.bp.csv_3.csv\n",
      "rest_cp_epocflex_2023.03.26t14.28.21+08.00.md.bp.csv_4.csv\n",
      "rest_cp_epocflex_2023.03.26t14.30.40+08.00.md.bp.csv_0.csv\n",
      "rest_cp_epocflex_2023.03.26t14.30.40+08.00.md.bp.csv_4.csv\n",
      "rest_cp_epocflex_2023.03.26t14.32.55+08.00.md.bp.csv_1.csv\n",
      "rest_cp_epocflex_2023.03.26t14.32.55+08.00.md.bp.csv_2.csv\n",
      "rest_cp_epocflex_2023.03.26t14.32.55+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_01_epocflex_179733_2023.03.18t09.39.31+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_01_epocflex_179733_2023.03.18t09.39.31+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_01_epocflex_179733_2023.03.18t09.39.31+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_01_epocflex_179733_2023.03.18t09.39.31+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_02_epocflex_179733_2023.03.18t09.43.21+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_02_epocflex_179733_2023.03.18t09.43.21+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_02_epocflex_179733_2023.03.18t09.43.21+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_04_epocflex_2023.03.22t16.41.16+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_04_epocflex_2023.03.22t16.41.16+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_04_epocflex_2023.03.22t16.41.16+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_05_epocflex_2023.03.22t16.43.35+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_05_epocflex_2023.03.22t16.43.35+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_05_epocflex_2023.03.22t16.43.35+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_05_epocflex_2023.03.22t16.43.35+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_05_epocflex_2023.03.22t16.43.35+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_06_epocflex_2023.03.22t16.46.00+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.20.49+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.20.49+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.20.49+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.23.18+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.23.18+08.00.md.bp.csv_2.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.23.18+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.26.19+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.26.19+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.26.19+08.00.md.bp.csv_2.csv\n",
      "walkbase_bke_01_epocflex_2023.03.22t15.55.54+08.00.md.bp.csv_0.csv\n",
      "walkbase_bke_01_epocflex_2023.03.22t15.55.54+08.00.md.bp.csv_1.csv\n",
      "walkbase_bke_01_epocflex_2023.03.22t15.55.54+08.00.md.bp.csv_2.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.00.39+08.00.md.bp.csv_1.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.00.39+08.00.md.bp.csv_2.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.00.39+08.00.md.bp.csv_4.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.03.07+08.00.md.bp.csv_0.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.03.07+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_01_epocflex_2023.03.22t16.23.52+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_01_epocflex_2023.03.22t16.23.52+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_01_epocflex_2023.03.22t16.23.52+08.00.md.bp.csv_4.csv\n",
      "walkbase_zyy_02_epocflex_2023.03.22t16.26.47+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_02_epocflex_2023.03.22t16.26.47+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_03_epocflex_2023.03.22t16.29.13+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_03_epocflex_2023.03.22t16.29.13+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_03_epocflex_2023.03.22t16.29.13+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_03_epocflex_2023.03.22t16.29.13+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_03_epocflex_2023.03.22t16.29.13+08.00.md.bp.csv_4.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t13.57.27+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t13.57.27+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t13.57.27+08.00.md.bp.csv_4.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.48.56+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.48.56+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.48.56+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.51.36+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.51.36+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.51.36+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.54.14+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.54.14+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.54.14+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.54.14+08.00.md.bp.csv_4.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.16.45+08.00.md.bp.csv_0.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.16.45+08.00.md.bp.csv_1.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.16.45+08.00.md.bp.csv_2.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.16.45+08.00.md.bp.csv_3.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.23.07+08.00.md.bp.csv_0.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.23.07+08.00.md.bp.csv_1.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.23.07+08.00.md.bp.csv_2.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.23.07+08.00.md.bp.csv_3.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.25.49+08.00.md.bp.csv_0.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.25.49+08.00.md.bp.csv_1.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.25.49+08.00.md.bp.csv_2.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.25.49+08.00.md.bp.csv_3.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.25.49+08.00.md.bp.csv_4.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.07.27+08.00.md.bp.csv_0.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.07.27+08.00.md.bp.csv_1.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.07.27+08.00.md.bp.csv_2.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.07.27+08.00.md.bp.csv_4.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.11.11+08.00.md.bp.csv_0.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.11.11+08.00.md.bp.csv_2.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.11.11+08.00.md.bp.csv_3.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.13.31+08.00.md.bp.csv_0.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.13.31+08.00.md.bp.csv_1.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.13.31+08.00.md.bp.csv_3.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.15.53+08.00.md.bp.csv_0.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.15.53+08.00.md.bp.csv_1.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.15.53+08.00.md.bp.csv_2.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.18.08+08.00.md.bp.csv_1.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.18.08+08.00.md.bp.csv_3.csv\n",
      "walkl_bke_01_epocflex_2023.03.22t16.00.31+08.00.md.bp.csv_0.csv\n",
      "walkl_bke_01_epocflex_2023.03.22t16.00.31+08.00.md.bp.csv_1.csv\n",
      "walkl_bke_01_epocflex_2023.03.22t16.00.31+08.00.md.bp.csv_2.csv\n",
      "walkl_bke_01_epocflex_2023.03.22t16.00.31+08.00.md.bp.csv_3.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.07.56+08.00.md.bp.csv_0.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.07.56+08.00.md.bp.csv_1.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.07.56+08.00.md.bp.csv_2.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.07.56+08.00.md.bp.csv_3.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.10.32+08.00.md.bp.csv_0.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.10.32+08.00.md.bp.csv_1.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.10.32+08.00.md.bp.csv_3.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.10.32+08.00.md.bp.csv_4.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.13.37+08.00.md.bp.csv_0.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.13.37+08.00.md.bp.csv_1.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.13.37+08.00.md.bp.csv_3.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.31.47+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.32.42+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.32.42+08.00.md.bp.csv_1.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.32.42+08.00.md.bp.csv_2.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.32.42+08.00.md.bp.csv_4.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_1.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_2.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_4.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_5.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_6.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_7.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_8.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_1.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_2.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_5.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.01.30+08.00.md.bp.csv_1.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.01.30+08.00.md.bp.csv_2.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.01.30+08.00.md.bp.csv_3.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.01.30+08.00.md.bp.csv_4.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.04.11+08.00.md.bp.csv_1.csv\n"
     ]
    }
   ],
   "source": [
    "train_file_list = os.listdir('C:/Users/a1882/Desktop/EEG/eegdata_3000/train')\n",
    "saved_path = os.getcwd()\n",
    "print(\"Current Working Directory is \" + saved_path)\n",
    "os.chdir(r\"C:\\Users\\a1882\\Desktop\\EEG\\eegdata_3000\\train\")\n",
    "for train_file_name in train_file_list:\n",
    "    print(train_file_name)\n",
    "os.chdir(saved_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.389842Z",
     "end_time": "2023-04-16T08:50:35.414839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lefthand', 'lefthand', 'lefthand', 'lefthand', 'lefthand', 'lefthand', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl']\n",
      "lefthand\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "for train_file_name in train_file_list:\n",
    "    train_labels.append(train_file_name.split('_')[0])\n",
    "\n",
    "print(train_labels)\n",
    "print(train_labels[3])\n",
    "\n",
    "label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "\n",
    "encode_labels  = [label_map[train_label] for train_label in train_labels]\n",
    "\n",
    "train_label = torch.tensor(encode_labels, dtype=torch.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.430838Z",
     "end_time": "2023-04-16T08:50:35.523663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory is C:\\Users\\a1882\\Desktop\\EEG\n",
      "lefthand_zyy_04_epocflex_2023.03.22t16.48.29+08.00.md.bp.csv_1.csv\n",
      "lefthand_zyy_05_epocflex_2023.03.22t16.50.54+08.00.md.bp.csv_0.csv\n",
      "lefthand_zyy_05_epocflex_2023.03.22t16.50.54+08.00.md.bp.csv_3.csv\n",
      "lefthand_zyy_05_epocflex_2023.03.22t16.50.54+08.00.md.bp.csv_4.csv\n",
      "read_bke_01_epocflex_2023.03.22t15.41.00+08.00.md.bp.csv_1.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_10.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_12.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_13.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_3.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_5.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_6.csv\n",
      "read_bke_02_epocflex_2023.03.22t15.48.25+08.00.md.bp.csv_8.csv\n",
      "read_bke_03_epocflex_2023.03.22t16.04.38+08.00.md.bp.csv_1.csv\n",
      "read_bke_04_epocflex_2023.03.22t16.07.02+08.00.md.bp.csv_2.csv\n",
      "read_bke_04_epocflex_2023.03.22t16.07.02+08.00.md.bp.csv_3.csv\n",
      "read_bke_04_epocflex_2023.03.22t16.07.02+08.00.md.bp.csv_4.csv\n",
      "rest_cp_epocflex_2023.03.26t14.28.21+08.00.md.bp.csv_2.csv\n",
      "rest_cp_epocflex_2023.03.26t14.30.40+08.00.md.bp.csv_1.csv\n",
      "rest_cp_epocflex_2023.03.26t14.30.40+08.00.md.bp.csv_2.csv\n",
      "rest_cp_epocflex_2023.03.26t14.30.40+08.00.md.bp.csv_3.csv\n",
      "rest_cp_epocflex_2023.03.26t14.32.55+08.00.md.bp.csv_0.csv\n",
      "rest_cp_epocflex_2023.03.26t14.32.55+08.00.md.bp.csv_3.csv\n",
      "rest_zyy_01_epocflex_179733_2023.03.18t09.39.31+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_02_epocflex_179733_2023.03.18t09.43.21+08.00.md.bp.csv_0.csv\n",
      "rest_zyy_02_epocflex_179733_2023.03.18t09.43.21+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_04_epocflex_2023.03.22t16.41.16+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_04_epocflex_2023.03.22t16.41.16+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.20.49+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.20.49+08.00.md.bp.csv_4.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.23.18+08.00.md.bp.csv_1.csv\n",
      "rest_zyy_epocflex_2023.03.26t15.23.18+08.00.md.bp.csv_4.csv\n",
      "walkbase_bke_01_epocflex_2023.03.22t15.55.54+08.00.md.bp.csv_3.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.00.39+08.00.md.bp.csv_0.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.00.39+08.00.md.bp.csv_3.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.03.07+08.00.md.bp.csv_1.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.03.07+08.00.md.bp.csv_3.csv\n",
      "walkbase_cp_epocflex_2023.03.26t14.03.07+08.00.md.bp.csv_4.csv\n",
      "walkbase_zyy_01_epocflex_2023.03.22t16.23.52+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_01_epocflex_2023.03.22t16.23.52+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_02_epocflex_2023.03.22t16.26.47+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_02_epocflex_2023.03.22t16.26.47+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t13.57.27+08.00.md.bp.csv_1.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t13.57.27+08.00.md.bp.csv_2.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.48.56+08.00.md.bp.csv_0.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.48.56+08.00.md.bp.csv_4.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.51.36+08.00.md.bp.csv_3.csv\n",
      "walkbase_zyy_epocflex_2023.03.26t14.54.14+08.00.md.bp.csv_1.csv\n",
      "walkfocus_cp_epocflex_2023.03.26t14.23.07+08.00.md.bp.csv_4.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.07.27+08.00.md.bp.csv_3.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.11.11+08.00.md.bp.csv_1.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.11.11+08.00.md.bp.csv_4.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.13.31+08.00.md.bp.csv_2.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.15.53+08.00.md.bp.csv_3.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.18.08+08.00.md.bp.csv_0.csv\n",
      "walkfocus_zyy_epocflex_2023.03.26t15.18.08+08.00.md.bp.csv_2.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.07.56+08.00.md.bp.csv_4.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.10.32+08.00.md.bp.csv_2.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.13.37+08.00.md.bp.csv_2.csv\n",
      "walkl_cp_epocflex_2023.03.26t14.13.37+08.00.md.bp.csv_4.csv\n",
      "walkl_zyy_01_epocflex_2023.03.22t16.32.42+08.00.md.bp.csv_3.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_3.csv\n",
      "walkl_zyy_02_epocflex_2023.03.22t16.35.38+08.00.md.bp.csv_9.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_3.csv\n",
      "walkl_zyy_epocflex_2023.03.26t14.58.03+08.00.md.bp.csv_4.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.01.30+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.04.11+08.00.md.bp.csv_0.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.04.11+08.00.md.bp.csv_2.csv\n",
      "walkl_zyy_epocflex_2023.03.26t15.04.11+08.00.md.bp.csv_3.csv\n"
     ]
    }
   ],
   "source": [
    "valid_file_list = os.listdir('C:/Users/a1882/Desktop/EEG/eegdata_3000/validation')\n",
    "saved_path = os.getcwd()\n",
    "print(\"Current Working Directory is \" + saved_path)\n",
    "os.chdir(r\"C:\\Users\\a1882\\Desktop\\EEG\\eegdata_3000\\validation\")\n",
    "for valid_file_name in valid_file_list:\n",
    "    print(valid_file_name)\n",
    "os.chdir(saved_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.455663Z",
     "end_time": "2023-04-16T08:50:35.525661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lefthand', 'lefthand', 'lefthand', 'lefthand', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'read', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'rest', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkbase', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkfocus', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl', 'walkl']\n",
      "lefthand\n"
     ]
    }
   ],
   "source": [
    "valid_labels = []\n",
    "for valid_file_name in valid_file_list:\n",
    "    valid_labels.append(valid_file_name.split('_')[0])\n",
    "\n",
    "print(valid_labels)\n",
    "print(valid_labels[3])\n",
    "\n",
    "label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "\n",
    "encode_labels  = [label_map[valid_label] for valid_label in valid_labels]\n",
    "\n",
    "valid_label = torch.tensor(encode_labels, dtype=torch.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.492660Z",
     "end_time": "2023-04-16T08:50:35.526663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_unique_objects = set(train_labels)\n",
    "train_class_number = len(train_unique_objects)\n",
    "print(train_class_number)\n",
    "\n",
    "valid_unique_objects = set(valid_labels)\n",
    "valid_class_number = len(valid_unique_objects)\n",
    "print(valid_class_number)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.514664Z",
     "end_time": "2023-04-16T08:50:35.706664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, filelist, root_dir,data_label,transform=None):\n",
    "        self.filelist = filelist\n",
    "        self.root_dir = root_dir\n",
    "        self.data_label = data_label\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print('index:', index, 'len(self.filelist):', len(self.filelist), 'len(self.data_label):', len(self.data_label))\n",
    "        data_label = self.data_label[index]\n",
    "        file_path = os.path.join(self.root_dir, self.filelist[index])\n",
    "        eeg_data = np.array(pd.read_csv(file_path))\n",
    "        return eeg_data, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.544663Z",
     "end_time": "2023-04-16T08:50:35.733659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=train_class_number):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(1, 4), stride=(1, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4))\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 4), stride=(1, 4))\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(47104, 128)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        #print('x:', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print('conv1:', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        #print('conv2:', x.shape)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print('flatten:', x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# model = EEGNet()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.591665Z",
     "end_time": "2023-04-16T08:50:35.734660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=( 1, 32, 3000), dtype=torch.float32)\n",
    "model = EEGNet()\n",
    "output = model(X)\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.689662Z",
     "end_time": "2023-04-16T08:50:35.838634Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(train_file_list, 'C:/Users/a1882/Desktop/EEG/eegdata_3000/train', train_label)\n",
    "valid_dataset = EEGDataset(valid_file_list, 'C:/Users/a1882/Desktop/EEG/eegdata_3000/validation', valid_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.846628Z",
     "end_time": "2023-04-16T08:50:35.912631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.862631Z",
     "end_time": "2023-04-16T08:50:35.913634Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.876631Z",
     "end_time": "2023-04-16T08:50:35.914630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.905630Z",
     "end_time": "2023-04-16T08:50:35.939633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            global train_loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "def test(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    global valid_loss\n",
    "    valid_loss.append(test_loss)\n",
    "    global accuracy\n",
    "    accuracy.append(correct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:50:35.943630Z",
     "end_time": "2023-04-16T08:50:36.006625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.843865  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 31.9%, Avg loss: 1.349684 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.614301  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 60.9%, Avg loss: 1.472428 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.316137  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 71.0%, Avg loss: 0.925430 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.079133  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 60.9%, Avg loss: 0.951058 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.889419  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 59.4%, Avg loss: 0.746130 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.735698  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 59.4%, Avg loss: 1.333450 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.709222  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 65.2%, Avg loss: 0.797765 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.598279  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 65.2%, Avg loss: 0.669700 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.474358  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 66.7%, Avg loss: 0.699854 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.494707  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.704491 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.503721  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.798567 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.370214  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 69.6%, Avg loss: 0.735001 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.408995  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 65.2%, Avg loss: 0.630882 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.259145  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 69.6%, Avg loss: 1.203618 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.375050  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 1.358514 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.283018  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.720282 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.308016  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.192412 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.304699  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.680515 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.261270  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.890489 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.210343  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.783463 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.259719  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.642332 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.165849  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.174916 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.196415  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.722999 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.162914  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.586405 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.232151  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.208832 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.174636  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.372039 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.193855  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.624661 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.155111  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.526062 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.114534  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.524660 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.211717  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.877106 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.295762  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.966012 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.174421  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.610958 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.176414  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.473305 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.066961  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.396476 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.163617  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.820754 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.157196  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.444444 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.171775  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.446541 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.225192  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.795640 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.146773  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.545475 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.105758  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.639671 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.114425  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.658970 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.125820  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.533845 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.113460  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.543188 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.047389  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 1.171192 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.112406  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.993871 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.100337  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.618293 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.043385  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 71.0%, Avg loss: 0.997495 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.101146  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.593732 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.033520  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.813688 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.082196  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.518793 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.146157  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.930323 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.146127  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.385843 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.098004  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.765116 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.064969  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 1.023279 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.066017  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 1.002027 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.129317  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.073895 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.073159  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.306180 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.088688  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 2.287704 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.046466  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.682048 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.063125  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 1.010626 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.176252  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.582818 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.065684  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.823471 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.040378  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 1.163223 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.097049  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.625583 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.122080  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.851713 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.097991  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.540283 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.049042  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.603108 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.090971  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.641238 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.036719  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.680901 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.068834  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.641147 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.027593  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.939915 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.027015  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 1.029984 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.068050  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.462893 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.061099  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.505187 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.043795  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.530376 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.062802  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.803311 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.053374  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.901332 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.031296  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.499329 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.080627  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.256629 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.026989  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.532784 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.035928  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.642565 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.058493  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.456194 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.014470  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.859180 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.034302  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.719833 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.046929  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.607651 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.020961  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.953453 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.020836  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.694950 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.046861  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.907508 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.050082  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.377854 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.057978  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 81.2%, Avg loss: 0.905350 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.042105  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.521999 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.010642  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.533241 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.039723  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.586039 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.044402  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.910750 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.029900  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.543601 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.028487  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.700644 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.037619  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.529992 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.018106  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.097949 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.048744  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.876167 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.054738  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.666149 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.040687  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.749506 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.023043  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.965266 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.062271  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.969681 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.022793  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.499625 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.035224  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 81.2%, Avg loss: 0.621927 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.024612  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.571266 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.022613  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.463076 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.037269  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.470748 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.044048  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.609826 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.015731  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.467093 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.031757  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.557736 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.023449  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.540743 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.044025  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.627710 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.032253  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.645562 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.047960  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.586536 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.009643  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.835770 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.038232  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.451682 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.023348  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.493112 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.025460  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.838547 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.028194  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.993769 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.024002  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.494886 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.023214  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.490308 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.013760  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 2.752336 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.027033  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.576227 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.022156  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.555439 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.019001  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.047173 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.042344  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 82.6%, Avg loss: 0.631954 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.024699  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 81.2%, Avg loss: 1.001785 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.016523  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.480150 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.020014  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.656546 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.026843  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.629269 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.010986  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.917757 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.024523  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 1.173845 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.013003  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.504855 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.008971  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.982468 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.012729  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.831840 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.003768  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.183778 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.022741  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 82.6%, Avg loss: 0.629572 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.031661  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 81.2%, Avg loss: 0.472547 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.031707  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 81.2%, Avg loss: 1.312471 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.035675  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 2.300267 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.036852  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.853463 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.017334  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 0.658646 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.019740  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.837027 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.015799  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 72.5%, Avg loss: 0.868561 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.020564  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 73.9%, Avg loss: 0.531119 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.006778  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.617909 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.033725  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.567717 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.011520  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.755235 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.007369  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.914105 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.018893  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.483191 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.025821  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.471360 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.035089  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.548523 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.010783  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 2.734846 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.028357  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.771272 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.018824  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.304714 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.006029  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.954416 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.038032  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.488419 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.011976  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.459713 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.017450  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.892653 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.043167  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 75.4%, Avg loss: 1.091378 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.027481  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.501524 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.003604  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.948828 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.015108  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.775533 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.006092  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.639189 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.008543  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.586598 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.012899  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.773493 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.022243  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.845664 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.065058  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.884265 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.025168  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.570637 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.051387  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.748465 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.029737  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 1.270092 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.047001  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 1.153825 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.014084  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.789484 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.090778  [    0/  161]\n",
      "Test Error:\n",
      " Accuracy: 76.8%, Avg loss: 0.891737 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# model = model = EEG_LSTM(input_size=31000, hidden_size=128, num_layers=2,num_classes=train_class_number).to(device)\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracy = []\n",
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    model.train(True)\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    model.train(False)\n",
    "    test(valid_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T23:17:18.337294Z",
     "end_time": "2023-04-16T02:22:06.752972Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss,'b',label='train loss')\n",
    "plt.ylabel('train loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(valid_loss,'r',label='valid loss')\n",
    "plt.ylabel('valid loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "#plt.save(os.path.join('C:/User/a1882/Desktop/EEG','loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:49:00.347823Z",
     "end_time": "2023-04-16T08:49:02.622530Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:49:02.626527Z",
     "end_time": "2023-04-16T08:49:02.787425Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy, 'b', label='accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "#plt.save(os.path.join('C:/User/a1882/Desktop/EEG','loss.png'))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T08:49:03.787960Z",
     "end_time": "2023-04-16T08:49:04.405585Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
