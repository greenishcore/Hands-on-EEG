{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:11:29.680171400Z",
     "start_time": "2023-05-03T02:11:06.029510200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "orgin_raw_data_dir = 'C:\\\\Users\\\\a1882\\\\Desktop\\\\EEG\\\\new_implement\\\\data\\\\orgin_raw_data_slid_window_slice_3000'\n",
    "model_save ='C:\\\\Users\\\\a1882\\\\Desktop\\\\EEG\\\\new_implement\\\\model'\n",
    "pic_dir = 'C:\\\\Users\\\\a1882\\\\Desktop\\\\EEG\\\\new_implement\\\\pic'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:11:29.875273500Z",
     "start_time": "2023-05-03T02:11:29.861259700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import torch\n",
    "def stackfy(fram):\n",
    "    stack = torch.zeros(32,4,389,515)\n",
    "    for i in range(32):\n",
    "        stack[i,:,:,:] = spect(fram.iloc[i,:].to_numpy())\n",
    "    return stack\n",
    "\n",
    "def spect(signa):\n",
    "    freq = 128\n",
    "    #t = np.arrange(0, 3000/freq, 1/freq)\n",
    "    freqs, times, Sx = signal.spectrogram(signa, freq)\n",
    "    amplitude = np.abs(Sx)\n",
    "    sp = plt.pcolormesh(times, freqs, np.log(amplitude), shading='gouraud')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('image.png', bbox_inches='tight')\n",
    "\n",
    "    # 加载图像，并将其转换为张量\n",
    "    image = plt.imread('image.png')\n",
    "    tensor_data = transforms.ToTensor()(image)\n",
    "    #tensor_data = tensor.permute(3,0,1,2)\n",
    "    return tensor_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:00.973805800Z",
     "start_time": "2023-05-03T02:27:00.883263200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = orgin_raw_data_dir\n",
    "        self.file_list = os.listdir(self.data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = pd.read_csv(file_path, header=None)\n",
    "        image_tensor = stackfy(data)\n",
    "        # tensor_data = transforms.ToTensor()(image)\n",
    "        #data = torch.from_numpy(data)\n",
    "        label_map = {'lefthand': 0, 'read': 1, 'rest': 2, 'walkbase': 3, 'walkl': 4 ,'walkfocus': 5}\n",
    "        data_label = label_map[file_name.split('_')[0]]\n",
    "        return image_tensor, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:01.490703Z",
     "start_time": "2023-05-03T02:27:01.403159900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "dataset = EEG_Dataset(orgin_raw_data_dir)\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset,valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size,valid_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:02.179667900Z",
     "start_time": "2023-05-03T02:27:01.956422300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4,16,kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(397312, 128)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = torch.unsqueeze(x, 1)\n",
    "        #print('x:', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print('conv1:', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        #print('conv2:', x.shape)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print('flatten:', x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:02.796941700Z",
     "start_time": "2023-05-03T02:27:02.687389100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6])\n",
      "tensor([[-0.2142,  0.6450,  0.5562, -0.1309,  0.0337, -0.5877],\n",
      "        [-0.6037, -0.7456, -0.1684,  0.3015,  0.5190, -0.8028],\n",
      "        [-0.3431,  0.0889,  0.4374, -0.4858,  0.5546,  0.2714],\n",
      "        [-0.0041,  0.6998, -0.3008, -0.2925, -0.1556, -0.0458],\n",
      "        [-0.1321,  0.5824, -0.1741,  0.0044,  0.3406, -0.3635],\n",
      "        [ 0.7098, -0.2050,  0.1032,  0.5484, -0.1634, -0.4252],\n",
      "        [ 0.2248,  0.8636, -0.0467,  0.0111, -0.9645,  0.2523],\n",
      "        [-0.3190,  0.4072, -0.0569,  0.6924, -0.3987, -0.7801],\n",
      "        [-0.2253,  0.1634,  0.4226,  0.0210, -0.2803,  0.1700],\n",
      "        [-0.2190,  0.3667, -0.0143,  0.1186,  0.1329, -0.2881],\n",
      "        [ 0.3635,  0.2349, -0.6687,  0.7852, -0.5489,  0.7517],\n",
      "        [-0.3214, -0.1219, -0.8454, -0.1205, -0.5269, -0.1026],\n",
      "        [-0.6181, -0.2581, -0.4741, -0.3671,  0.3630, -0.6121],\n",
      "        [ 0.4167,  0.3888,  0.0135,  0.0412, -0.9213,  0.1639],\n",
      "        [-0.4514, -0.5191, -0.4278, -0.7156,  0.4302, -0.4205],\n",
      "        [-0.2421, -0.4968, -0.0110, -0.1407, -0.2556, -1.3996],\n",
      "        [-0.3168, -0.3435, -0.7710, -0.3546,  0.1849, -0.8208],\n",
      "        [ 0.0226, -0.0166,  0.2127,  0.3033,  0.1910,  0.2262],\n",
      "        [ 0.1553,  0.6318, -0.3021, -0.4310, -0.4033,  0.2574],\n",
      "        [-0.0733, -0.4859, -0.3746, -0.7116, -0.1212, -0.0090],\n",
      "        [-0.2227,  0.3410, -0.0479,  0.3843,  0.0502, -0.7074],\n",
      "        [-0.1035,  0.2797, -0.6291,  0.6377,  0.1885, -0.4743],\n",
      "        [ 1.1350, -0.4106, -0.2525,  0.8055,  0.2625, -0.6743],\n",
      "        [ 0.2481,  0.1529, -0.7856,  0.3242, -1.0967,  0.1220],\n",
      "        [-0.0050,  0.7090, -0.1455, -0.0089, -0.0324,  0.0673],\n",
      "        [-0.4102,  0.3449, -1.2223,  0.3564, -0.5332, -0.2190],\n",
      "        [-0.1475, -0.2912, -0.1124,  0.2334,  0.0308, -0.2637],\n",
      "        [-0.7626,  0.1581, -0.1191, -0.1519, -0.1235, -0.2496],\n",
      "        [-0.1058,  0.2321,  0.2819,  1.0007, -0.1833, -0.3189],\n",
      "        [ 0.0714,  0.4142, -0.8043,  0.4677, -0.6529,  0.4875],\n",
      "        [ 0.2348,  0.1353,  0.1046, -0.2062, -0.7426, -0.1053],\n",
      "        [ 0.0376, -0.1609,  0.7118, -0.3047, -0.5147,  0.0563]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(32,4,389,515), dtype=torch.float32)\n",
    "model = EEGNet()\n",
    "output = model(X)\n",
    "print(output.shape)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:32.068866600Z",
     "start_time": "2023-05-03T02:27:03.170158700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "# device = (\"cpu\")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:27:32.291575800Z",
     "start_time": "2023-05-03T02:27:32.085863700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 30\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:18:27.109008100Z",
     "start_time": "2023-05-03T02:18:27.037002900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            global train_loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "\n",
    "def valid(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    valid_loss, valid_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            valid_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    valid_loss /= num_batches\n",
    "    valid_correct /= size\n",
    "    print(f\"Valid Error:\\n Accuracy: {(100 * valid_correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "    global validloss\n",
    "    validloss.append(valid_loss)\n",
    "    global validaccuracy\n",
    "    validaccuracy.append(valid_correct)\n",
    "\n",
    "\n",
    "def test(dataloader, model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    global testloss\n",
    "    testloss.append(test_loss)\n",
    "    global testaccuracy\n",
    "    testaccuracy.append(correct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T02:18:28.010707900Z",
     "start_time": "2023-05-03T02:18:27.791623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1882\\AppData\\Local\\Temp\\ipykernel_1440\\983192831.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  sp = plt.pcolormesh(times, freqs, np.log(amplitude), shading='gouraud')\n"
     ]
    }
   ],
   "source": [
    "# model = model.cuda()\n",
    "train_loss = []\n",
    "validloss = []\n",
    "testloss = []\n",
    "validaccuracy = []\n",
    "testaccuracy = []\n",
    "for t in range(num_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    model.train(True)\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    model.train(False)\n",
    "    test(valid_loader, model, loss_fn)\n",
    "\n",
    "    model.train(False)\n",
    "    test(test_loader, model, loss_fn)\n",
    "\n",
    "    if t > num_epochs-5:\n",
    "        torch.save(model.state_dict(), 'cnn_3000_30e_'+str(t)+'.pt')\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-03T02:27:39.443920400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
